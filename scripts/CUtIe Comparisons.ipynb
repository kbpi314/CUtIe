{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "import click\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def calculate_cutie(label, samp_var1_fp, delimiter1, samp_var2_fp, delimiter2, \n",
    "                    f1type, f2type, working_dir, skip, startcol, endcol, \n",
    "                    statistic, resample_k, rm_zero, paired, alpha, mc, fold, \n",
    "                    fold_value, n_replicates,method):\n",
    "\n",
    "    # calculate_cutie()\n",
    "    start_time = time.clock()\n",
    "\n",
    "    # file handling and parsing decisions\n",
    "    # file 1 is the 'dominant' file type and should always contain the OTU file\n",
    "    # we let the dominant fil 'override' the sample_id list ordering\n",
    "    samp_ids, var2_names, samp_to_var2, n_var2, n_samp = \\\n",
    "        parse_input(f2type, samp_var2_fp, startcol, endcol, delimiter2, skip)\n",
    "    samp_ids, var1_names, samp_to_var1, n_var1, n_samp = \\\n",
    "        parse_input(f1type, samp_var1_fp, startcol, endcol, delimiter1, skip)\n",
    "\n",
    "    # temporary printing of samp and var names for reference\n",
    "    print samp_ids[0:5]\n",
    "    print var1_names[0:5]\n",
    "\n",
    "    # convert dictionaries to matrices\n",
    "    samp_var1, avg_var1, norm_avg_var1, var_var1, norm_var_var1, skew_var1 = \\\n",
    "        dict_to_matrix(samp_to_var1, samp_ids)\n",
    "    samp_var2, avg_var2, norm_avg_var2, var_var2, norm_var_var2, skew_var2 = \\\n",
    "        dict_to_matrix(samp_to_var2, samp_ids)\n",
    "\n",
    "    ###\n",
    "    # Simple Linear Regression: Spearman and Pearson\n",
    "    ### \n",
    "    # statistic-specific initial output\n",
    "    stat_to_matrix = assign_statistics(samp_var1, samp_var2, \n",
    "                                                  statistic, rm_zero)\n",
    "\n",
    "    # unpack statistic matrices\n",
    "    pvalues = stat_to_matrix['pvalues']\n",
    "    corrs = stat_to_matrix['correlations']\n",
    "    logpvals = stat_to_matrix['logpvals']\n",
    "    r2vals = stat_to_matrix['r2vals']\n",
    "\n",
    "    # determine significance threshold and number of correlations\n",
    "    threshold, n_corr = set_threshold(pvalues, alpha, mc, paired)\n",
    "\n",
    "    # calculate initial sig candidates\n",
    "    initial_sig, all_pairs = initial_sig_SLR(n_var1, n_var2, \n",
    "        pvalues, threshold, paired)\n",
    "\n",
    "    # calculate true sig based on cutie resampling\n",
    "    initial_insig = set(all_pairs).difference(initial_sig)\n",
    "\n",
    "    # return sets of interest; some of these will be empty dicts depending on the statistic\n",
    "    (true_sig, TP_comb_to_rev, \n",
    "     P_worst_p, P_worst_r, \n",
    "     false_insig, FN_comb_to_rev, \n",
    "     N_best_p, N_best_r) = updatek_cutie_SLR(initial_insig, \n",
    "            initial_sig, pvalues, samp_var1, samp_var2, threshold, \n",
    "            resample_k, corrs, fold, fold_value, working_dir, method,\n",
    "            paired, statistic, n_replicates)\n",
    "\n",
    "    print time.clock() - start_time\n",
    "    return samp_ids, samp_var1, samp_var2, var1_names, var2_names, initial_sig, initial_insig, true_sig, \\\n",
    "        TP_comb_to_rev, P_worst_p, P_worst_r, \\\n",
    "        false_insig, FN_comb_to_rev, N_best_p, N_best_r\n",
    "\n",
    "print 'Done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from itertools import izip\n",
    "from scipy import stats\n",
    "\n",
    "def mapping_parse (samp_meta_file, startcol=17, endcol=100, delimiter='\\t'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    samp_ids = []\n",
    "    samp_meta = {}\n",
    "    # generate metabolite list from the 0th line (header)\n",
    "    # default assumes metabolites are in col 17 to 99\n",
    "    meta_names = samp_meta_file.readline().split(delimiter)[startcol:endcol]\n",
    "    # for the remainder of the lines (i.e. the non-header lines)\n",
    "    for line in samp_meta_file:\n",
    "        if line != '\\n':\n",
    "            line = line.split('\\n')[0]\n",
    "            line = line.split(delimiter)\n",
    "            samp_ids.append(line[0]) # line[0] is the sample id\n",
    "            metabolite_levels = [np.nan if x == '' else float(x) for x in \\\n",
    "                line[startcol:endcol]]\n",
    "            while len(metabolite_levels) < len(meta_names):\n",
    "                metabolite_levels.append(np.nan)\n",
    "            samp_meta[line[0]] = metabolite_levels\n",
    "    n_meta = len(meta_names)\n",
    "    n_samp = len(samp_ids)\n",
    "    print 'The length of mapping_variables is ' + str(n_meta)\n",
    "    print 'The number of samples is ' + str(n_samp)\n",
    "    return samp_ids, meta_names, samp_meta, n_meta, n_samp\n",
    "\n",
    "\n",
    "def otu_parse(samp_bact_file, delimiter = '\\t', skip = 1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # create lists (corresponding to smoking and non-smoking files) \n",
    "    bact_names = []\n",
    "    samp_bact = {}\n",
    "    \n",
    "    for i in xrange(skip):\n",
    "        samp_bact_file.readline() # line 0 is 'constructed from biom file' \n",
    "\n",
    "    samp_ids = samp_bact_file.readline().rstrip().split(delimiter)\n",
    "    samp_ids.pop(0) # the 0th entry is a header\n",
    "    for samp_id in samp_ids:\n",
    "        samp_bact[samp_id] = []\n",
    "\n",
    "    for line in samp_bact_file:\n",
    "        if line is not '': \n",
    "            split_line = line.rstrip().split(delimiter)\n",
    "            # the 0th entry is the name of an OTU\n",
    "            bact_names.append(split_line[0])\n",
    "            split_line.pop(0) # pop off OTU\n",
    "            for b in xrange(len(split_line)):\n",
    "                samp_bact[samp_ids[b]].append(split_line[b])\n",
    "        \n",
    "    n_bact = len(bact_names)\n",
    "    n_samp = len(samp_ids)\n",
    "\n",
    "    print 'The length of samp_ids is ' + str(n_samp)\n",
    "    print 'The length of bact_names is ' + str(n_bact)\n",
    "\n",
    "    return samp_ids, bact_names, samp_bact, n_bact, n_samp\n",
    "\n",
    "def parse_input(ftype, fp, startcol, endcol, delimiter, skip):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # some files like the mapping file won't split on \\n but will on \\rU\n",
    "    if ftype == 'map':\n",
    "        with open(fp,'rU') as f:    \n",
    "            samp_ids, var_names, samp_to_var, n_var, n_samp = \\\n",
    "                mapping_parse(f, startcol, endcol, delimiter)\n",
    "   \n",
    "    elif ftype == 'otu':\n",
    "        with open(fp, 'rU') as f:\n",
    "            samp_ids, var_names, samp_to_var, n_var, n_samp = \\\n",
    "                otu_parse(f, delimiter, skip)     \n",
    "\n",
    "    return samp_ids, var_names, samp_to_var, n_var, n_samp \n",
    "\n",
    "def dict_to_matrix(samp_dict, samp_ids):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize matrix; # rows = # of samp_ids, # cols = # entries per key\n",
    "    rows = len(samp_ids)\n",
    "    cols = len(samp_dict[samp_dict.keys()[0]])\n",
    "    samp_matrix = np.zeros(shape=(rows,cols))    \n",
    "    \n",
    "    # populate matrix from the dict\n",
    "    for r in xrange(rows):\n",
    "        for c in xrange(cols):\n",
    "            samp_matrix[r][c] = samp_dict[samp_ids[r]][c]\n",
    "\n",
    "    # retrieve mean values and normalize\n",
    "    avg_matrix = np.array([np.nanmean(samp_matrix,0)])\n",
    "    norm_avg_matrix = avg_matrix - avg_matrix.min()\n",
    "    norm_avg_matrix = norm_avg_matrix/norm_avg_matrix.max()\n",
    "\n",
    "    # retrieve variances and normalize\n",
    "    var_matrix = np.array([np.nanvar(samp_matrix,0)])\n",
    "    norm_var_matrix = var_matrix - var_matrix.min()\n",
    "    norm_var_matrix = norm_var_matrix/var_matrix.max()\n",
    "\n",
    "    skew_matrix = np.array([[stats.skew(samp_matrix[:,x],nan_policy='omit') \\\n",
    "        for x in xrange(cols)]])\n",
    "    return samp_matrix, avg_matrix, norm_avg_matrix,var_matrix,norm_var_matrix, skew_matrix\n",
    "    \n",
    "def read_taxa(t):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    parts = t.split(';')\n",
    "    while parts:\n",
    "        if not parts[-1].endswith('__'):\n",
    "            t1 = parts[-2].split('__')[1]\n",
    "            t2 = parts[-1].split('__')[1]\n",
    "            return t1 + ' ' + t2\n",
    "        else:\n",
    "            parts.pop()\n",
    "\n",
    "    # This should not be reached: \"k__;p__...\"\n",
    "    return 'Uncharacterized'\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "    \n",
    "import os\n",
    "import math\n",
    "import itertools    \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from cutie import parse\n",
    "from cutie import output\n",
    "\n",
    "def initial_stats_SLR(samp_var1, samp_var2, functions, mapf, f_stats, rm_zero = False):\n",
    "    \"\"\" \n",
    "    INPUTS\n",
    "    samp_var1: np array where row i col j corresponds to level of var1 j in \n",
    "               sample i\n",
    "    samp_var2: np array where row i col j corresponds to level of var2 j in \n",
    "               sample i                  \n",
    "    functions: list of strings of function names \n",
    "    mapf:      dict that maps function name to function object\n",
    "    f_stats:   dict that maps function name to list of output strings\n",
    "    rm_zero:   remove values that are 0 in both x and y\n",
    "\n",
    "    OUTPUTS\n",
    "    statistics: list of dict where each dict corresponds to each element \n",
    "                in function in the order they are passed and where each \n",
    "                key corresponds to a particular statistic calculated by \n",
    "                each function in functions and the element is an array \n",
    "                where row i col j corresponds to the value of a given \n",
    "                statistic to the values for var1 row i and var2 col j.\n",
    "     \n",
    "    FUNCTION\n",
    "    Function that computes an initial set of statistics per the specified \n",
    "    functions. Returns a dict where the key is a statistical function and  \n",
    "    the element is an initial matrix with dimensions n_rel_stats x n_var1 x \n",
    "    n_var2, corresponding to the relevant statistics from simple linear \n",
    "    regression (SLR) between each var1 and var2. \n",
    "    \"\"\"\n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    stat_dict = {}\n",
    "    \n",
    "    # retrieve relevant stats and create dictionary entry, 3D array\n",
    "    for f in functions:\n",
    "        rel_stats = f_stats[f]\n",
    "        stat_dict[f] = np.zeros((len(rel_stats), \n",
    "                                 n_var1, \n",
    "                                 n_var2))\n",
    "\n",
    "    # subset the data matrices into the cols needed\n",
    "    for var1 in xrange(n_var1):\n",
    "        for var2 in xrange(n_var2):\n",
    "            var1_values = samp_var1[:,var1]\n",
    "            var2_values = samp_var2[:,var2] \n",
    "            # remove zero values\n",
    "            stacked = np.stack([var1_values,var2_values],0)\n",
    "            if rm_zero is True:\n",
    "                stacked = stacked[:,~np.all(stacked == 0.0, axis = 0)]\n",
    "            # remove NANs\n",
    "            stacked = stacked[:,np.all(~np.isnan(stacked), axis = 0)]\n",
    "            var1_values = stacked[0]\n",
    "            var2_values = stacked[1]\n",
    "            for f in functions:\n",
    "                # values is a list of the relevant_stats in order\n",
    "                if len(var1_values) == 0 or len(var2_values) == 0: \n",
    "                    values = np.zeros([len(f_stats[f])])\n",
    "                    values[:] = np.nan\n",
    "                else:\n",
    "                    values = mapf[f](var1_values, var2_values)\n",
    "                for s in xrange(len(values)):\n",
    "                    stat_dict[f][s][var1][var2] = values[s] \n",
    "    \n",
    "    return stat_dict \n",
    "\n",
    "def assign_statistics(samp_var1, samp_var2, statistic, rm_zero = False):\n",
    "    \"\"\"\n",
    "    samp_var1: np array where row i col j corresponds to level of var1 j in \n",
    "               sample i\n",
    "    samp_var2: np array where row i col j corresponds to level of var2 j in \n",
    "               sample i        \n",
    "    statistic: statistic of choice (e.g. kpc)\n",
    "    rm_zero:   boolean whether zeros should be removed\n",
    "    \"\"\"\n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    stat_to_matrix = {}\n",
    "\n",
    "    if (statistic == 'kpc' or statistic == 'jkp' or statistic == 'rpc' or \n",
    "        statistic == 'bsp' or statistic == 'rjkp' or statistic == 'rbsp'):\n",
    "\n",
    "        # define function and dictionary mapping string to function for statistic of interest\n",
    "        functions = ['stats.linregress']\n",
    "        mapf = {'stats.linregress': stats.linregress}\n",
    "        f_stats = {'stats.linregress': \n",
    "                   ['b1', 'b0', 'pcorr','ppvalue','stderr']}\n",
    "        stat_dict = initial_stats_SLR(samp_var1, samp_var2, functions, mapf,\n",
    "                                      f_stats)\n",
    "        \n",
    "        stat_to_matrix['pvalues'] = stat_dict['stats.linregress'][3]\n",
    "        stat_to_matrix['correlations'] = stat_dict['stats.linregress'][2]\n",
    "        stat_to_matrix['logpvals'] = np.log(stat_dict['stats.linregress'][3])\n",
    "        stat_to_matrix['r2vals'] = np.square(stat_dict['stats.linregress'][2])\n",
    "\n",
    "    elif statistic == 'ksc':\n",
    "        functions = ['stats.spearmanr']\n",
    "        mapf = {'stats.spearmanr': stats.spearmanr}\n",
    "        f_stats = {\n",
    "        'stats.spearmanr': ['scorr','spvalue']}\n",
    "\n",
    "        stat_dict = initial_stats_SLR(samp_var1, samp_var2, functions, mapf, \n",
    "                                      f_stats)\n",
    "        \n",
    "        stat_to_matrix['pvalues'] = stat_dict['stats.spearmanr'][1]\n",
    "        stat_to_matrix['logpvals'] = np.log(stat_to_matrix['pvalues'])\n",
    "        stat_to_matrix['correlations'] = stat_dict['stats.spearmanr'][0]\n",
    "        stat_to_matrix['r2vals'] = [] # filler\n",
    "\n",
    "    else:\n",
    "        print 'Invalid statistic chosen'\n",
    "\n",
    "    return stat_to_matrix\n",
    "\n",
    "def set_threshold(pvalues, alpha, mc, paired = False):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    pvalues: 2D np array of pvalues\n",
    "    alpha:   float of original cutoff\n",
    "    mc:      form of multiple corrections to use\n",
    "             nomc: none\n",
    "             bc: bonferroni\n",
    "             fwer: family-wise error rate \n",
    "             fdr: false discovery rate\n",
    "    paired:  boolean, true if correlations are between a single matrix \n",
    "\n",
    "    OUTPUTS\n",
    "    threshold: float cutoff of pvalues\n",
    "\n",
    "    FUNCTION\n",
    "    Performs a multiple comparisons correction on the alpha value\n",
    "    \"\"\"\n",
    "    print 'The type of mc correction used was ' + mc\n",
    "    pvalues_copy = np.copy(pvalues)\n",
    "    if paired == True:\n",
    "        # fill the upper diagonal with nan as to not double count pvalues in FDR\n",
    "        pvalues_copy[np.triu_indices(pvalues_copy.shape[1],0)] = np.nan\n",
    "        # currently computing all pairs double counting\n",
    "        n_corr = np.size(pvalues_copy,1) * (np.size(pvalues_copy,1) - 1)#/2)\n",
    "    else:\n",
    "        n_corr = np.size(pvalues_copy,0) * np.size(pvalues_copy,1)\n",
    "\n",
    "    # determine threshold based on multiple comparisons setting\n",
    "    pvalues_copy = np.sort(pvalues_copy.flatten())\n",
    "    pvalues_copy = pvalues_copy[~np.isnan(pvalues_copy)]\n",
    "    if mc == 'nomc':\n",
    "        threshold = alpha\n",
    "    elif mc == 'bc':\n",
    "        threshold = alpha / pvalues_copy.size\n",
    "    elif mc == 'fwer':\n",
    "        threshold = 1.0 - (1.0 - alpha) ** (1/(pvalues_copy.size))\n",
    "    elif mc == 'fdr':\n",
    "        # compute FDR cutoff\n",
    "        cn = 1.0\n",
    "        thresholds = np.array([(float(k+1))/(len(pvalues_copy))\n",
    "            * alpha / cn for k in xrange(len(pvalues_copy))])\n",
    "        compare = np.where(pvalues_copy <= thresholds)[0]\n",
    "        if len(compare) is 0:\n",
    "            threshold = alpha\n",
    "            print 'Warning: no p-values below threshold, defaulted with min(p) = ' \\\n",
    "                + str(min(pvalues_copy))\n",
    "        else:\n",
    "            threshold = thresholds[max(compare)]\n",
    "    print 'The threshold value was ' + str(threshold)\n",
    "    return threshold, n_corr\n",
    "\n",
    "\n",
    "def initialize_headers(infln_metrics):\n",
    "    \"\"\"\n",
    "    Initialize headers for R matrix\n",
    "    \"\"\"\n",
    "    headers = ['var1_index','var2_index','sample_number','var1_value', \\\n",
    "                'var2_value','initial_sig']\n",
    "\n",
    "    for metric in infln_metrics:\n",
    "        # populate headers\n",
    "        headers.append(metric + '_indicator')\n",
    "        headers.append(metric + '_cutoff')\n",
    "        headers.append(metric + '_strength')\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def calculate_intersection(names, sets):\n",
    "    '''\n",
    "    Calculates intersection of items in sets for all regions\n",
    "    e.g. \n",
    "    names = ['a','b','c']\n",
    "    sets = [set_a, set_b, set_c] where set_i = set([1,2,3])\n",
    "    '''\n",
    "    # temporary mapping of name  to set\n",
    "    name_to_set = {}\n",
    "    for i in xrange(len(names)):\n",
    "        name_to_set[names[i]] = sets[i]\n",
    "\n",
    "    # get regions and initialize default dict of list\n",
    "    regions = []\n",
    "    for i in xrange(1, len(names)+1):\n",
    "        els = [list(x) for x in itertools.combinations(names, i)]\n",
    "        regions.extend(els)\n",
    "    regions_set = defaultdict(list)\n",
    "\n",
    "    # create union of sets\n",
    "    union_set = set()\n",
    "    for indiv_set in sets:\n",
    "        union_set = union_set.union(indiv_set)\n",
    "\n",
    "    # for each region, determine in_set and out_set\n",
    "    for region in regions:\n",
    "        in_set = set(region)\n",
    "        out_set = set(names).difference(in_set)\n",
    "\n",
    "        # for each in_set,     \n",
    "        final_set = union_set\n",
    "        for in_s in in_set:\n",
    "            final_set = final_set.intersection(name_to_set[in_s])\n",
    "\n",
    "        for out_s in out_set:\n",
    "            final_set = final_set.difference(name_to_set[out_s])\n",
    "\n",
    "        regions_set[str(region)] = final_set\n",
    "\n",
    "        print 'The amount of unique elements in set ' + str(region) + ' is ' + str(len(final_set))\n",
    "    \n",
    "    return regions, regions_set\n",
    "\n",
    "\n",
    "\n",
    "def get_param(samp_var1, samp_var2):\n",
    "    \"\"\"\n",
    "    Extracts number of variables and samples\n",
    "    \"\"\"\n",
    "    n_var1 = np.size(samp_var1, 1)\n",
    "    n_var2 = np.size(samp_var2, 1)\n",
    "    n_samp = np.size(samp_var1, 0)\n",
    "\n",
    "    return n_var1, n_var2, n_samp\n",
    "\n",
    "\n",
    "def initial_sig_SLR(n_var1, n_var2, pvalues, threshold, paired):\n",
    "    \"\"\"\n",
    "    Determine list of initially significant candidate correlations\n",
    "    \"\"\"\n",
    "    initial_sig = []\n",
    "    all_pairs = []\n",
    "    for var1 in xrange(n_var1): \n",
    "        for var2 in xrange(n_var2): \n",
    "            pair = (var1,var2)\n",
    "            if not (paired and (var1 == var2)):\n",
    "                all_pairs.append(pair)\n",
    "            # if variables are paired i.e. the same, then don't compute corr(i,i)\n",
    "            if pvalues[var1][var2] < threshold and not (paired and (var1 == var2)):\n",
    "                initial_sig.append(pair)\n",
    "    \n",
    "    print 'The length of initial_sig is ' + str(len(initial_sig))\n",
    "    print 'The length of initial_insig is ' + \\\n",
    "        str(len(set(all_pairs).difference(set(initial_sig))))\n",
    "    return initial_sig, all_pairs\n",
    "\n",
    "\n",
    "###\n",
    "# RESAMPLE K\n",
    "###\n",
    "\n",
    "\n",
    "def updatek_cutie_SLR(initial_insig, initial_sig, pvalues, samp_var1, samp_var2, \n",
    "    threshold, resample_k, corrs, fold, fold_value, working_dir, method,\n",
    "    paired = False, statistic = 'kpc', n_replicates = 1000):\n",
    "    \"\"\"\n",
    "    Perform cutie resampling up to k points or other statistical analysis\n",
    "    \"\"\"\n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    # raise error if resampling too many points\n",
    "    if resample_k > n_samp - 3:\n",
    "        raise ValueError('Too many points specified for resampling for size %s' \n",
    "            % (str(len(samp_ids))))\n",
    "    \n",
    "    (true_sig, TP_comb_to_rev, \n",
    "     P_worst_p, P_worst_r, \n",
    "     false_insig, FN_comb_to_rev, \n",
    "     N_best_p, N_best_r) = initialize_stat_dicts(resample_k, n_var1, n_var2)\n",
    "\n",
    "    # separate FP and TP\n",
    "    if (statistic == 'kpc' or statistic == 'ksc' or statistic == 'jkp' or \n",
    "        statistic == 'bsp'):\n",
    "        (true_sig, TP_comb_to_rev, P_worst_p, P_worst_r, samp_counter, \n",
    "         var1_counter, var2_counter) = cutiek_true_sig(initial_sig, samp_var1,\n",
    "            samp_var2, pvalues, corrs, threshold, paired, statistic, resample_k, \n",
    "            P_worst_p, P_worst_r, true_sig, TP_comb_to_rev, fold, fold_value, \n",
    "            n_replicates, method)\n",
    "\n",
    "    # separate FN and TN\n",
    "    if (statistic == 'rpc' or statistic == 'rsc' or statistic == 'rjkp' or \n",
    "        statistic == 'rbsp'): \n",
    "        (false_insig, FN_comb_to_rev, N_best_p, N_best_r, samp_counter, \n",
    "         var1_counter, var2_counter) = cutiek_false_insig(initial_insig, \n",
    "            samp_var1, samp_var2, pvalues, corrs, threshold, paired, statistic, \n",
    "            resample_k, N_best_p, N_best_r, false_insig, FN_comb_to_rev, fold, \n",
    "            fold_value, n_replicates, method)\n",
    "\n",
    "    # output histograms/plots showing sample and variable appearance among CUtIe's\n",
    "    output.diag_hist(samp_counter, var1_counter, var2_counter, resample_k, \n",
    "                     working_dir)\n",
    "\n",
    "    return (true_sig, TP_comb_to_rev, P_worst_p, P_worst_r, false_insig, \n",
    "            FN_comb_to_rev, N_best_p, N_best_r)\n",
    "\n",
    "\n",
    "def cutiek_true_sig(initial_sig, samp_var1, samp_var2, pvalues, corrs, \n",
    "    threshold, paired, statistic, resample_k, P_worst_p, P_worst_r, true_sig, \n",
    "    TP_comb_to_rev, fold, fold_value, n_replicates, method):\n",
    "    \"\"\"\n",
    "    Determine true significant correlatoins via resampling of k points\n",
    "    \"\"\"     \n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "    # diagnostic statistics\n",
    "    samp_counter = {}\n",
    "    var1_counter = {}\n",
    "    var2_counter = {}\n",
    "\n",
    "    # initialize counter dictionaries for tracking sample and variable freq in CUtIe's\n",
    "    for i in xrange(resample_k):\n",
    "        samp_counter[str(i+1)] = np.zeros(n_samp)\n",
    "        var1_counter[str(i+1)] = np.zeros(np.size(samp_var1,1))\n",
    "        var2_counter[str(i+1)] = np.zeros(np.size(samp_var2,1)) \n",
    "\n",
    "    for pair in initial_sig:\n",
    "        var1, var2 = pair\n",
    "        # obtain sign of correlation\n",
    "        sign = np.sign(corrs[var1][var2])\n",
    "\n",
    "        insig = np.zeros(n_samp) # indicators for whether correlation is insig or not\n",
    "        rev_corr = np.zeros(n_samp) # indicators for whether a sign reverses\n",
    "        \n",
    "        # resample_k = number of points being resampled\n",
    "        for i in xrange(resample_k):\n",
    "            new_rev_corr, new_insig, max_maxp, min_minr = evaluate_correlation_k(\n",
    "                var1, var2, n_samp, samp_var1, samp_var2, pvalues, threshold, \n",
    "                statistic, i, sign, fold, fold_value, n_replicates, method) \n",
    "\n",
    "            # update the insig-indicators for the k-th resample iteration\n",
    "            insig = np.add(insig, new_insig)\n",
    "            rev_corr = np.add(rev_corr, new_rev_corr)\n",
    "\n",
    "            # update the correlation within the resample_k dictionary\n",
    "            P_worst_p[str(i+1)][var1][var2] = max_maxp\n",
    "            P_worst_r[str(i+1)][var1][var2] = min_minr\n",
    "\n",
    "            # sums to 0\n",
    "            if insig.sum() == 0:\n",
    "                true_sig[str(i+1)].append(pair)\n",
    "                if rev_corr.sum() != 0:\n",
    "                    TP_comb_to_rev[str(i+1)].append(pair)\n",
    "\n",
    "            samp_counter[str(i+1)] = np.add(samp_counter[str(i+1)], insig)\n",
    "            var1_counter[str(i+1)][var1] += 1\n",
    "            var2_counter[str(i+1)][var2] += 1\n",
    "\n",
    "    return (true_sig, TP_comb_to_rev, P_worst_p, P_worst_r, samp_counter, \n",
    "            var1_counter, var2_counter)\n",
    "\n",
    "\n",
    "\n",
    "def cutiek_false_insig(initial_insig, samp_var1, samp_var2, pvalues, corrs, \n",
    "    threshold, paired, statistic, resample_k, N_best_p, N_best_r, false_insig, \n",
    "    FN_comb_to_rev, fold, fold_value, n_replicates, method):\n",
    "    \"\"\"\n",
    "    Determine true significant correlatoins via resampling of k points\n",
    "    \"\"\"      \n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    # diagnostic statistics\n",
    "    samp_counter = {}\n",
    "    var1_counter = {}\n",
    "    var2_counter = {}\n",
    "\n",
    "    # initialize counter dictionaries for tracking sample and variable freq in CUtIe's\n",
    "    for i in xrange(resample_k):\n",
    "        samp_counter[str(i+1)] = np.zeros(n_samp)\n",
    "        var1_counter[str(i+1)] = np.zeros(np.size(samp_var1,1))\n",
    "        var2_counter[str(i+1)] = np.zeros(np.size(samp_var2,1)) \n",
    "\n",
    "    for pair in initial_insig:\n",
    "        var1, var2 = pair\n",
    "        # obtain sign of correlation\n",
    "        sign = np.sign(corrs[var1][var2])\n",
    "\n",
    "        insig = np.zeros(n_samp) # indicators for whether correlation is insig or not\n",
    "        rev_corr = np.zeros(n_samp) # indicators for whether a sign reverses\n",
    "        \n",
    "        # resample_k = number of points being resampled\n",
    "        for i in xrange(resample_k):\n",
    "            new_rev_corr, new_insig, min_minp, max_maxr = evaluate_correlation_k(\n",
    "                var1, var2, n_samp, samp_var1, samp_var2, pvalues, threshold, \n",
    "                statistic, i, sign, fold, fold_value, n_replicates, method) \n",
    "\n",
    "            # update the insig-indicators for the k-th resample iteration\n",
    "            insig = np.add(insig, new_insig)\n",
    "            rev_corr = np.add(rev_corr, new_rev_corr)\n",
    "\n",
    "            # update the correlation within the resample_k dictionary\n",
    "            N_best_p[str(i+1)][var1][var2] = min_minp\n",
    "            N_best_r[str(i+1)][var1][var2] = max_maxr\n",
    "\n",
    "            # sums to 0\n",
    "            if insig.sum() != 0:\n",
    "                false_insig[str(i+1)].append(pair)\n",
    "                if rev_corr.sum() != 0:\n",
    "                    FN_comb_to_rev[str(i+1)].append(pair)\n",
    "\n",
    "            samp_counter[str(i+1)] = np.add(samp_counter[str(i+1)], insig)\n",
    "            var1_counter[str(i+1)][var1] += 1\n",
    "            var2_counter[str(i+1)][var2] += 1\n",
    "\n",
    "    return (false_insig, FN_comb_to_rev, N_best_p, N_best_r, samp_counter, \n",
    "            var1_counter, var2_counter)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_correlation_k(var1, var2, n_samp, samp_var1, samp_var2, pvalues, \n",
    "    threshold, statistic, i, sign, fold, fold_value, n_replicates, method):\n",
    "    \"\"\"\n",
    "    Evaluate a given var1, var2 correlation at the resample_k = i level \n",
    "    \"\"\"\n",
    "\n",
    "    if statistic == 'kpc':\n",
    "        new_rev_corr, new_insig, maxp, minr = resamplek_cutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, i + 1, sign, fold, \n",
    "            fold_value)\n",
    "\n",
    "    elif statistic == 'rpc':\n",
    "        new_rev_corr, new_insig, minp, maxr = reversek_cutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, i + 1, sign, fold,\n",
    "            fold_value)\n",
    "\n",
    "    elif statistic == 'ksc':\n",
    "        new_rev_corr, new_insig, maxp, minr = resamplek_cutie_sc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, i + 1, sign, fold, \n",
    "            fold_value)\n",
    "\n",
    "    elif statistic == 'jkp':\n",
    "        new_rev_corr, new_insig, maxp, minr = jackknifek_cutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, i + 1, sign, method)\n",
    "\n",
    "    elif statistic == 'bsp':\n",
    "        new_rev_corr, new_insig, maxp, minr = bootstrap_cutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, sign, method,\n",
    "            n_replicates)\n",
    "\n",
    "    elif statistic == 'rjkp':\n",
    "        new_rev_corr, new_insig, minp, maxr= jackknifek_revcutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, i + 1, sign, method)\n",
    "\n",
    "    elif statistic == 'rbsp':\n",
    "        new_rev_corr, new_insig, minp, maxr = bootstrap_revcutie_pc(var1, var2, \n",
    "            n_samp, samp_var1, samp_var2, pvalues, threshold, sign, method,\n",
    "            n_replicates)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid statistic chosen %s' % statistic)\n",
    "    \n",
    "    # obtain most extreme p and R-sq values\n",
    "    if (statistic == 'kpc' or statistic == 'ksc' or statistic == 'jkp' or \n",
    "        statistic == 'bsp'):\n",
    "        extrema_p = np.max(maxp)\n",
    "        extrema_r = np.min(minr)\n",
    "\n",
    "    elif (statistic == 'rpc' or statistic == 'rsc' or statistic == 'rjkp' or \n",
    "          statistic == 'rbsp'):\n",
    "        extrema_p = np.min(minp)\n",
    "        extrema_r = np.max(maxr)\n",
    "\n",
    "    return new_rev_corr, new_insig, extrema_p, extrema_r\n",
    "\n",
    "\n",
    "def compute_pc(new_var1, new_var2):\n",
    "    \"\"\"\n",
    "    compute pearson correlation and return p and r values\n",
    "    \"\"\"\n",
    "\n",
    "    # if resulting variables do not contain enough points\n",
    "    if new_var1.size < 2 or new_var2.size < 2:\n",
    "        p_value = 1\n",
    "        r_value = 0\n",
    "\n",
    "    else:\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "                                                        new_var1, new_var2)\n",
    "    # if p_value is nan\n",
    "    if np.isnan(p_value):\n",
    "        p_value = 1\n",
    "        r_value = 0\n",
    "\n",
    "    return p_value, r_value\n",
    "\n",
    "\n",
    "def update_rev_maxp_minr(sign, r_value, p_value, indices, reverse, maxp, minr):\n",
    "    \"\"\"\n",
    "    Check sign, r and p value and update reverse, maxp, and minr\n",
    "    \"\"\"\n",
    "    # if sign has reversed\n",
    "    if np.sign(r_value) != sign:\n",
    "        for i in indices:\n",
    "            reverse[i] += 1\n",
    "\n",
    "    # update most extreme p and r values\n",
    "    for i in indices:\n",
    "        if p_value > maxp[i]:\n",
    "            maxp[i] = p_value\n",
    "        if np.absolute(r_value) < np.absolute(minr[i]):\n",
    "            minr[i] = r_value\n",
    "\n",
    "    return reverse, maxp, minr\n",
    "\n",
    "\n",
    "def update_revrev_minp_maxr(sign, r_value, p_value, indices, reverse, minp, maxr):\n",
    "    \"\"\"\n",
    "    Check sign, r and p value and update reverse, maxp, and minr\n",
    "    \"\"\"\n",
    "    # if sign has reversed\n",
    "    if np.sign(r_value) != sign:\n",
    "        for i in indices:\n",
    "            reverse[i] += 1\n",
    "\n",
    "    # update most extreme p and r values\n",
    "    for i in indices:\n",
    "        if p_value < minp[i]:\n",
    "            minp[i] = p_value\n",
    "        if np.absolute(r_value) > np.absolute(maxr[i]):\n",
    "            maxr[i] = r_value\n",
    "\n",
    "    return reverse, minp, maxr\n",
    "\n",
    "def init_var_indicators(var1_index, var2_index, samp_var1, samp_var2):\n",
    "    \"\"\"\n",
    "    Initialize indicator matrices and variable matrices\n",
    "    \"\"\"\n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    exceeds = np.zeros(n_samp)\n",
    "    reverse = np.zeros(n_samp)\n",
    "    maxp = np.zeros(n_samp)\n",
    "    minr = np.ones(n_samp)\n",
    "\n",
    "    # slice relevant variables\n",
    "    var1 = samp_var1[:,var1_index]\n",
    "    var2 = samp_var2[:,var2_index]\n",
    "    return exceeds, reverse, maxp, minr, var1, var2 \n",
    "\n",
    "\n",
    "def init_rev_var_indicators(var1_index, var2_index, samp_var1, samp_var2):\n",
    "    \"\"\"\n",
    "    Initialize indicator matrices and variable matrices\n",
    "    \"\"\"\n",
    "    n_var1, n_var2, n_samp = get_param(samp_var1, samp_var2)\n",
    "\n",
    "    exceeds = np.zeros(n_samp)\n",
    "    reverse = np.zeros(n_samp)\n",
    "    minp = np.ones(n_samp)\n",
    "    maxr = np.zeros(n_samp)\n",
    "\n",
    "    # slice relevant variables\n",
    "    var1 = samp_var1[:,var1_index]\n",
    "    var2 = samp_var2[:,var2_index]\n",
    "    return exceeds, reverse, minp, maxr, var1, var2 \n",
    "\n",
    "def remove_nans(var1, var2):\n",
    "    \"\"\"\n",
    "    Remove Nan Points\n",
    "    # remove all points where one or both values are NAN\n",
    "    # new_var1 = np.array([1,2,np.nan])\n",
    "    # new_var2 = np.array([1,np.nan,3])\n",
    "    # stacked = array([[  1.,   2.,  nan],\n",
    "    #                  [  1.,  nan,   3.]])\n",
    "    # np.isnan(stacked) = array([[False, False,  True],\n",
    "    #                             [False,  True, False]], dtype=bool)\n",
    "    # np.all(~np.isnan(stacked), axis = 0) = array([ True, False, False], dtype=bool)\n",
    "    # stacked[:,np.all(~np.isnan(stacked), axis = 0)] =  array([[ 1.],\n",
    "    #                                                           [ 1.]])\n",
    "    \"\"\"\n",
    "    stacked = np.stack([var1, var2], 0)\n",
    "    stacked = stacked[:,np.all(~np.isnan(stacked), axis = 0)]\n",
    "    new_var1 = stacked[0]\n",
    "    new_var2 = stacked[1]\n",
    "    return new_var1, new_var2\n",
    "\n",
    "def jackknifek_cutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, resample_k, sign, method):\n",
    "    \"\"\"\n",
    "    Perform jackknife resampling using Pearson\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, maxp, minr, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "    #corr_nan = False\n",
    "    p_values = []\n",
    "    # iteratively delete k samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), resample_k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)), indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)), indices)]\n",
    "\n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "        # if p-value is nan; break loop and set exceeds += 1\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, maxp, minr = update_rev_maxp_minr(sign, r_value, p_value,\n",
    "                                                   indices, reverse, maxp, minr)\n",
    "\n",
    "        p_values.append(p_value)\n",
    "\n",
    "\n",
    "    # generate log confidence interval on p-value\n",
    "    CI, p_mu, p_sigma = get_pCI(np.array(p_values), n_samp, method)\n",
    "\n",
    "    # test confidence interval\n",
    "    exceeds = test_upper_CI(CI, threshold, exceeds, [item for sublist in combs for item in sublist], method)\n",
    "\n",
    "    return reverse, exceeds, maxp, minr\n",
    "\n",
    "\n",
    "def jackknifek_revcutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, resample_k, sign, method):\n",
    "    \"\"\"\n",
    "    Perform reverse jackknife resampling using Pearson\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, minp, maxr, var1, var2 = init_rev_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    p_values = []\n",
    "    # iteratively delete k samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), resample_k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)), indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)), indices)]\n",
    "\n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, maxp, minr = update_revrev_minp_maxr(sign, r_value, p_value,\n",
    "                                                   indices, reverse, minp, maxr)\n",
    "\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # generate log confidence interval on p-value\n",
    "    CI, p_mu, p_sigma = get_pCI(np.array(p_values), n_samp, method)\n",
    "\n",
    "    # test confidence interval\n",
    "    # https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python    \n",
    "    exceeds = test_lower_CI(CI, threshold, exceeds, [item for sublist in combs for item in sublist], method)\n",
    "\n",
    "    return reverse, exceeds, minp, maxr\n",
    "\n",
    "def bootstrap_cutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, sign, method, n_replicates = 1000):\n",
    "    \"\"\"\n",
    "    Bootstrap resampling, n_replicates and log P confidence interval\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, maxp, minr, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    p_values = []\n",
    "\n",
    "    for k in xrange(n_replicates):\n",
    "        new_samp = np.random.choice(xrange(n_samp), size=n_samp, replace=True)\n",
    "        new_var1 = []\n",
    "        new_var2 = []\n",
    "        for j in xrange(n_samp):\n",
    "            new_var1.append(var1[new_samp[j]])\n",
    "            new_var2.append(var2[new_samp[j]])\n",
    "    \n",
    "\n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, maxp, minr = update_rev_maxp_minr(sign, r_value, p_value,\n",
    "                                                   xrange(n_samp), reverse, maxp, minr)\n",
    "        \n",
    "        p_values.append(p_value)\n",
    "\n",
    "    CI, p_mu, p_sigma = get_pCI(np.array(p_values), n_samp, method)\n",
    "\n",
    "    exceeds = test_upper_CI(CI, threshold, exceeds, xrange(n_samp), method)\n",
    "       \n",
    "    #maxp = [CI[1]] * n_samp \n",
    "\n",
    "\n",
    "    return reverse, exceeds, maxp, minr\n",
    "   \n",
    "\n",
    "\n",
    "def bootstrap_revcutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, sign, method, n_replicates = 1000):\n",
    "    \"\"\"\n",
    "    Bootstrap resampling, n_replicates and log P confidence interval\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, minp, maxr, var1, var2 = init_rev_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    p_values = []\n",
    "\n",
    "    for k in xrange(n_replicates):\n",
    "        new_samp = np.random.choice(xrange(n_samp), size=n_samp, replace=True)\n",
    "        new_var1 = []\n",
    "        new_var2 = []\n",
    "        for j in xrange(n_samp):\n",
    "            new_var1.append(var1[new_samp[j]])\n",
    "            new_var2.append(var2[new_samp[j]])\n",
    "    \n",
    "\n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, minp, maxr = update_revrev_minp_maxr(sign, r_value, p_value,\n",
    "                                                   xrange(n_samp), reverse, minp, maxr)\n",
    "        \n",
    "        p_values.append(p_value)\n",
    "\n",
    "    CI, p_mu, p_sigma = get_pCI(np.array(p_values), n_samp, method)\n",
    "\n",
    "    exceeds = test_lower_CI(CI, threshold, exceeds, xrange(n_samp), method)\n",
    "       \n",
    "    #maxp = [CI[1]] * n_samp \n",
    "\n",
    "    return reverse, exceeds, minp, maxr\n",
    "   \n",
    "def reversek_cutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, resample_k, sign, fold, fold_value):\n",
    "    \"\"\"\n",
    "    Perform cutie to detect FN\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    # exceeds, reverse, maxp, minr, var1, var2 \n",
    "    exceeds, reverse, maxr, minp, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    # iteratively delete two samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), resample_k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)),indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)),indices)]\n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "        if fold:\n",
    "            if (p_value < threshold and \\\n",
    "                p_value < pvalues[var1_index][var2_index] * fold_value) or \\\n",
    "                np.isnan(p_value):\n",
    "                for i in indices:\n",
    "                    exceeds[i] += 1\n",
    "        elif p_value < threshold or np.isnan(p_value): \n",
    "            for i in indices:\n",
    "                exceeds[i] += 1 # exceeds is a good thing here!\n",
    "\n",
    "\n",
    "        if np.sign(r_value) != sign:\n",
    "            for i in indices:\n",
    "                reverse[i] += 1\n",
    "\n",
    "        for i in indices:\n",
    "            if p_value < minp[i]:\n",
    "                minp[i] = p_value\n",
    "            if r_value > np.absolute(maxr[i]):\n",
    "                maxr[i] = r_value\n",
    "\n",
    "    return reverse, exceeds, minp, maxr\n",
    "\n",
    "def resamplek_cutie_pc(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, resample_k, sign, fold, fold_value):\n",
    "    \"\"\"     \n",
    "    INPUTS\n",
    "    var1_index: integer of var1 (in var1_names) to be evaluated\n",
    "    var2_index: integer of var1 (in var2_names) to be evaluated\n",
    "    n_samp:     integer of number of samples\n",
    "    samp_var1:  np array where row i col j indicates level of bact j \n",
    "                for sample i\n",
    "    samp_var2:  np array where row i col j indicates level of meta j \n",
    "                for sample i\n",
    "    pvalues:    np array of pvalues\n",
    "    threshold:  float of level of significance testing (after MC)\n",
    "    sign:       original sign of correlation to check against following re-evaluation\n",
    "    fold:       boolean if using 100x criterion for identifying cuties\n",
    "\n",
    "    OUTPUTS\n",
    "    reverse: array where index i is 1 if the correlation changes sign upon removing\n",
    "             sample i \n",
    "    exceeds: array where index i is x if removing that sample causes the \n",
    "             correlation to become insignificant in x different pairwise correlations\n",
    "    maxp:    maximum p-value observed via resampling k points\n",
    "    minr:    minimum p-value observed via resampling k points \n",
    "\n",
    "    FUNCTION\n",
    "    Takes a given bacteria and metabolite by index and recomputes pearson correlation \n",
    "    by removing 1 out of n (sample_size) points from samp_ids. \n",
    "    Returns an indicator array where exceeds[i] is 1 if removing that sample causes\n",
    "    the correlation to become insignificant in k different pairwise correlations\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, maxp, minr, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    # iteratively delete k samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), resample_k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)),indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)),indices)]\n",
    "       \n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_pc(new_var1, new_var2)\n",
    "\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, maxp, minr = update_rev_maxp_minr(sign, r_value, p_value,\n",
    "                                                   indices, reverse, maxp, minr)\n",
    "        \n",
    "        if fold:\n",
    "            if (p_value > threshold and \\\n",
    "                p_value > pvalues[var1_index][var2_index] * fold_value) or \\\n",
    "                np.isnan(p_value):\n",
    "                for i in indices:\n",
    "                    exceeds[i] += 1\n",
    "        elif p_value > threshold or np.isnan(p_value): \n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "\n",
    "    return reverse, exceeds, maxp, minr\n",
    "    \n",
    "def resamplek_cutie_sc(var1_index, var2_index, n_samp, samp_var1, \n",
    "    samp_var2, pvalues, threshold, k, sign, fold, fold_value, rm_zero = False):\n",
    "    \"\"\"     \n",
    "    INPUTS\n",
    "    rm_zero:          remove values that are 0 in both x and y\n",
    "        \n",
    "    OUTPUTS\n",
    "    reverse: array where index i is 1 if the correlation changes sign upon removing\n",
    "             sample i \n",
    "    exceeds: array where index i is k if removing that sample causes the \n",
    "             correlation to become insignificant in k different pairwise correlations\n",
    "    \n",
    "    FUNCTION\n",
    "    Takes a given bacteria and metabolite by index and recomputes spearman correlation \n",
    "    by removing 1 out of n (sample_size) points from samp_ids. \n",
    "    Returns an indicator array where exceeds[i] is 1 if removing that sample causes\n",
    "    the correlation to become insignificant in k different pairwise correlations\n",
    "    \"\"\"\n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, maxp, minr, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    # iteratively delete two samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)),indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)),indices)]\n",
    "        stacked = np.stack([new_var1,new_var2],0)\n",
    "        if rm_zero is True:\n",
    "            stacked = stacked[:,~np.all(stacked == 0.0, axis = 0)]\n",
    "        stacked = stacked[:,np.all(~np.isnan(stacked), axis = 0)]\n",
    "        new_var1 = stacked[0]\n",
    "        new_var2 = stacked[1]\n",
    "\n",
    "\n",
    "        if new_var1.size <= 3 or new_var2.size <= 3:\n",
    "            p_value = 1\n",
    "            corr = 0\n",
    "        else:\n",
    "            corr, p_value = stats.spearmanr(new_var1, new_var2)\n",
    "        if fold:\n",
    "            if (p_value > threshold and p_value > pvalues[var1_index][var2_index] * fold_value) or np.isnan(p_value): # or np.sign(corr) != sign:\n",
    "                for i in indices:\n",
    "                    exceeds[i] += 1\n",
    "        elif p_value > threshold or np.isnan(p_value): # or np.sign(corr) != sign:\n",
    "            for i in indices:\n",
    "                    exceeds[i] += 1\n",
    "        if np.sign(corr) != sign:\n",
    "            for i in indices:\n",
    "                reverse[i] += 1\n",
    "        \n",
    "        for i in indices:\n",
    "            if p_value > maxp[i]:\n",
    "                maxp[i] = p_value\n",
    "            if corr < np.absolute(minr[i]):\n",
    "                minr[i] = corr\n",
    "\n",
    "    return reverse, exceeds, maxp, minr\n",
    "\n",
    "def get_pCI(p_values, n_samp, method = 'log', zero_replace = 10e-100):\n",
    "    \"\"\"\n",
    "    Compute logp confidence interval\n",
    "    \"\"\"\n",
    "    method = str(method)\n",
    "    if method == 'log':\n",
    "        p_values[p_values == 0] = zero_replace\n",
    "        logp_values = np.log(p_values)\n",
    "        p_mu = np.mean(logp_values)\n",
    "        p_sigma = np.std(logp_values)\n",
    "    elif method == 'cbrt':\n",
    "        cbrtp_values = np.cbrt(p_values)\n",
    "        p_mu = np.mean(cbrtp_values)\n",
    "        p_sigma = np.std(cbrtp_values)\n",
    "    elif method == 'none':\n",
    "        p_mu = np.mean(p_values)\n",
    "        p_sigma = np.std(p_values)\n",
    "\n",
    "    pCI = (p_mu - 1.96 * p_sigma / np.sqrt(n_samp), p_mu + 1.96 * p_sigma / np.sqrt(n_samp))\n",
    "\n",
    "    return pCI, p_mu, p_sigma\n",
    "\n",
    "def test_upper_CI(CI, threshold, exceeds, indices, method = 'log'):\n",
    "    \"\"\"\n",
    "    Test if upper bound of CI is above a threshold and update exceeds indicator matrix\n",
    "    \"\"\"\n",
    "\n",
    "    method = str(method)\n",
    "    if method == 'log':\n",
    "        if CI[1] > np.log(threshold):\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "    elif method == 'cbrt':\n",
    "        if CI[1] > np.cbrt(threshold):\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "    elif method == 'none':\n",
    "        if CI[1] > threshold:\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "\n",
    "    return exceeds \n",
    "\n",
    "\n",
    "def test_lower_CI(CI, threshold, exceeds, indices, method = 'log'):\n",
    "    \"\"\"\n",
    "    Test if lower bound of CI is below a threshold and update exceeds indicator matrix\n",
    "    \"\"\"\n",
    "    method = str(method)\n",
    "    if method == 'log':\n",
    "        if CI[0] < np.log(threshold):\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "    elif method == 'cbrt':\n",
    "        if CI[0] < np.cbrt(threshold):\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "    elif method == 'none':\n",
    "        if CI[0] < threshold:\n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "    return exceeds \n",
    "\n",
    "def initialize_stat_dicts(resample_k, n_var1, n_var2):\n",
    "    \"\"\"\n",
    "    Create empty dicts\n",
    "    \"\"\"\n",
    "    # create dicts of points to track true_sig and reversed-sign correlations\n",
    "    true_sig = {}\n",
    "    false_insig = {}\n",
    "    FN_comb_to_rev = {}\n",
    "    TP_comb_to_rev = {} \n",
    "\n",
    "    # create matrices dict to hold the most extreme values of p and r (for R-sq)\n",
    "    P_worst_p = {}\n",
    "    P_worst_r = {}\n",
    "    N_best_p = {}\n",
    "    N_best_r = {}\n",
    "\n",
    "    # initialize dictionary entries as empty lists\n",
    "    for i in xrange(resample_k):\n",
    "        true_sig[str(i+1)] = []\n",
    "        TP_comb_to_rev[str(i+1)] = []\n",
    "        P_worst_p[str(i+1)] = np.zeros([n_var1, n_var2])\n",
    "        P_worst_r[str(i+1)] = np.ones([n_var1, n_var2])\n",
    "        \n",
    "        false_insig[str(i+1)] = []\n",
    "        FN_comb_to_rev[str(i+1)] = []\n",
    "        N_best_p[str(i+1)] = np.ones([n_var1, n_var2])\n",
    "        N_best_r[str(i+1)] = np.zeros([n_var1, n_var2])\n",
    "\n",
    "    return (true_sig, TP_comb_to_rev, P_worst_p, P_worst_r, false_insig, \n",
    "            FN_comb_to_rev, N_best_p, N_best_r)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of samp_ids is 50\n",
      "The length of bact_names is 500\n",
      "The length of samp_ids is 50\n",
      "The length of bact_names is 500\n",
      "['s0', 's1', 's2', 's3', 's4']\n",
      "['o0', 'o1', 'o2', 'o3', 'o4']\n",
      "The type of mc correction used was fdr\n",
      "The threshold value was 0.00133306613226\n",
      "The length of initial_sig is 6652\n",
      "The length of initial_insig is 242848\n",
      "144.573884\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:108: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "label = 'L6'\n",
    "samp_var1_fp = 'data/simulated_data/input_tables/ts_1/txts/table_2.txt'\n",
    "samp_var2_fp = 'data/simulated_data/input_tables/ts_1/txts/table_2.txt'\n",
    "f1type = 'otu'\n",
    "f2type = 'otu' \n",
    "working_dir = 'data_analysis/sim_ts3_kpc1fdr0.05/'\n",
    "skip = 1\n",
    "statistic = 'kpc'\n",
    "resample_k = 1\n",
    "paired = True\n",
    "alpha = 0.05\n",
    "mc = 'fdr'\n",
    "\n",
    "# defaults\n",
    "delimiter1 = '\\t'\n",
    "delimiter2 = '\\t'\n",
    "startcol = 17\n",
    "endcol = 100\n",
    "rm_zero = False\n",
    "fold = True\n",
    "fold_value = 1\n",
    "n_replicates = 100\n",
    "method = 'none'\n",
    "\n",
    "samp_ids, samp_var1, samp_var2, var1_names, var2_names, initial_sig, initial_insig, true_sig, TP_comb_to_rev, P_worst_p, P_worst_r, \\\n",
    "        placeholder1, placeholder2, placeholder3, placeholder4 = calculate_cutie(label, samp_var1_fp, delimiter1, \n",
    "                                                                          samp_var2_fp, delimiter2, \n",
    "                    f1type, f2type, working_dir, skip, startcol, endcol, \n",
    "                    statistic, resample_k, rm_zero, paired, alpha, mc, fold, \n",
    "                    fold_value, n_replicates,method)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of samp_ids is 50\n",
      "The length of bact_names is 500\n",
      "The length of samp_ids is 50\n",
      "The length of bact_names is 500\n",
      "['s0', 's1', 's2', 's3', 's4']\n",
      "['o0', 'o1', 'o2', 'o3', 'o4']\n",
      "The type of mc correction used was fdr\n",
      "The threshold value was 0.00133306613226\n",
      "The length of initial_sig is 6652\n",
      "The length of initial_insig is 242848\n",
      "4044.19012\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:108: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "label = 'L6'\n",
    "samp_var1_fp = 'data/simulated_data/input_tables/ts_1/txts/table_2.txt'\n",
    "samp_var2_fp = 'data/simulated_data/input_tables/ts_1/txts/table_2.txt'\n",
    "f1type = 'otu'\n",
    "f2type = 'otu' \n",
    "working_dir = 'data_analysis/sim_ts3_kpc1fdr0.05/'\n",
    "skip = 1\n",
    "statistic = 'rpc'\n",
    "resample_k = 1\n",
    "paired = True\n",
    "alpha = 0.05\n",
    "mc = 'fdr'\n",
    "\n",
    "# defaults\n",
    "delimiter1 = '\\t'\n",
    "delimiter2 = '\\t'\n",
    "startcol = 17\n",
    "endcol = 100\n",
    "rm_zero = False\n",
    "fold = True\n",
    "fold_value = 1\n",
    "n_replicates = 100\n",
    "method = 'none'\n",
    "\n",
    "samp_ids, samp_var1, samp_var2, var1_names, var2_names, initial_sig, initial_insig, placeholder5, placeholder6, placeholder7, placeholder8, \\\n",
    "        false_insig, FN_comb_to_rev, N_best_p, N_best_r = calculate_cutie(label, samp_var1_fp, delimiter1, \n",
    "                                                                          samp_var2_fp, delimiter2, \n",
    "                    f1type, f2type, working_dir, skip, startcol, endcol, \n",
    "                    statistic, resample_k, rm_zero, paired, alpha, mc, fold, \n",
    "                    fold_value, n_replicates,method)\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(samp_var1_fp, sep=\"\\t\", header=0, skiprows=1)\n",
    "df = df.set_index('#OTU ID').T\n",
    "#data.columns = [\"a\", \"b\", \"c\", \"etc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input from script: mine_fp = otu_table_small.MSQ34_L6.csv, label = 'otu'\n",
    "# obtain MINE output for full dataset \n",
    "# results stored in otu_table_small.MSQ34_L6.csv,allpairs,cv=0.1,B=n^0.6,Results.csv\n",
    "# parameters are default, will be changed if needed\n",
    "\n",
    "# sed script to delete one column at a time\n",
    "\n",
    "\n",
    "#if mine_non_par == True:\n",
    "# subset data files  \n",
    "# PP package, forkfun\n",
    "parse.subset_data(n_samp, transposed_fn, transposed_fp, working_dir)\n",
    "\n",
    "def subset_data(n_samp, transposed_fn, transposed_fp, working_dir):\n",
    "    for k in xrange(n_samp): \n",
    "        resample_fp = working_dir + str(k) + '_' + transposed_fn\n",
    "        if os.path.isfile(resample_fp) == False:\n",
    "            # sed to delete row\n",
    "            # sed is 1 indexed, the top row is the header, hence the k + 2\n",
    "            os.system(\"sed \" + str(k+2)+ \"d \" + transposed_fp + \" > \" + \\\n",
    "                resample_fp)\n",
    "    return\n",
    "\n",
    "# run MINE on each subset\n",
    "statistics.mine_subsets(n_samp, transposed_fn, transposed_fp, \\\n",
    "                        original_mine_fp, working_dir, label)\n",
    "\n",
    "def mine_subsets(n_samp, transposed_fn, transposed_fp, original_mine_fp, working_dir, label):\n",
    "    # resample_fp = working_dir/0_otu_transpose_table_small.MSQ34_L6.csv\n",
    "    for k in xrange(n_samp): \n",
    "        resample_fp = working_dir + str(k) + '_' + transposed_fn\n",
    "        # check if MINE results file for subset exists\n",
    "        # example original_mine_fp:\n",
    "        # otu_table_small.MSQ34_L6.csv,allpairs,cv=0.1,B=n^0.6,Results.csv\n",
    "        # original_mine_fp.split(label)[1] = \\\n",
    "        # _table_small.MSQ34_L6.csv,allpairs,cv=0.1,B=n^0.6,Results.csv\n",
    "        # subset_output_fp = working_dir/ + 0 + _ + otu + \\\n",
    "        # _table_small.MSQ34_L6.csv,allpairs,cv=0.1,B=n^0.6,Results.csv\n",
    "        subset_output_fp = working_dir + str(k) + '_' + label + \\\n",
    "            original_mine_fp.split(label)[1]\n",
    "\n",
    "        if os.path.isfile(subset_output_fp) == False:\n",
    "            os.system(\"java -jar ../MINE/MINE.jar \" + resample_fp + \\\n",
    "                \" '-allPairs' cv=0.1 exp=0.6 c=10 fewBoxes\")\n",
    "\n",
    "return \n",
    "\n",
    "# declare initial stats to parsex\n",
    "# provide statistic headers as headers in MINE output are less wieldy\n",
    "mine_stats = ['MIC_str','MIC_nonlin','MAS_nonmono','MEV_func',\n",
    "              'MCN_comp','linear_corr'] \n",
    "with open(original_mine_fp, 'rU') as f:\n",
    "    stat_to_matrix = parse.parse_mine(f, n_var1, var1_names, \n",
    "                                        mine_stats, mine_delimiter)\n",
    "\n",
    "with open(minep_fp, 'rU') as f:\n",
    "    mine_bins, pvalues_ordered = parse.parse_minep(f, mine_delimiter,\n",
    "                                                     pskip)\n",
    "\n",
    "#print mine_bins\n",
    "#print pvalues_ordered\n",
    "# Store MINE_str and compute pvalue for each correlation \n",
    "mine_str = stat_to_matrix['MIC_str']\n",
    "mine_nonlin = stat_to_matrix['MIC_nonlin']\n",
    "mine_pvalues = \n",
    "\n",
    "# Exhaustively parse all subsetted files and store results in 3d arrays\n",
    "mine_subset_str, mine_subset_p, mine_subset_nonlin = statistics.subset_mine(\n",
    "                        n_samp, n_var1, var1_names, label, mine_stats, \n",
    "                        pvalues_ordered, mine_bins, working_dir, \n",
    "                        original_mine_fp, mine_delimiter)\n",
    "\n",
    "# set FDR threshold\n",
    "threshold, n_corr = statistics.set_threshold(mine_pvalues, alpha, mc, \n",
    "                                                paired)\n",
    "\n",
    "# split into initial sig and true sig\n",
    "initial_sig, true_sig = statistics.cutie_mine(n_samp, n_var1, threshold, \n",
    "                                            mine_pvalues, mine_subset_p)\n",
    "### initial statistics       \n",
    "print 'Length of initial sig MINE is ' + str(len(initial_sig))\n",
    "print 'Length of true sig MINE is ' + str(len(true_sig['1']))\n",
    "\n",
    "\n",
    "# obtain worst_mine_p value and worst_mine_str for each \n",
    "worst_mine_p = np.amax(mine_subset_p, axis=0)\n",
    "worst_mine_str = np.amin(mine_subset_str, axis=0)\n",
    "max_mine_subset_nonlin = np.amax(mine_subset_nonlin, axis=0)\n",
    "min_mine_subset_nonlin = np.amin(mine_subset_nonlin, axis=0)\n",
    "\n",
    "# empty dictionary as placeholder\n",
    "P_comb_to_rev = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s40</th>\n",
       "      <th>s41</th>\n",
       "      <th>s42</th>\n",
       "      <th>s43</th>\n",
       "      <th>s44</th>\n",
       "      <th>s45</th>\n",
       "      <th>s46</th>\n",
       "      <th>s47</th>\n",
       "      <th>s48</th>\n",
       "      <th>s49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o0</th>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>0.272251</td>\n",
       "      <td>0.719604</td>\n",
       "      <td>63.118556</td>\n",
       "      <td>5.116637</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.113538</td>\n",
       "      <td>0.134295</td>\n",
       "      <td>0.150017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044790</td>\n",
       "      <td>0.332401</td>\n",
       "      <td>5.440243</td>\n",
       "      <td>0.899963</td>\n",
       "      <td>3.689245</td>\n",
       "      <td>0.527316</td>\n",
       "      <td>8.582046</td>\n",
       "      <td>866.065909</td>\n",
       "      <td>2.522821</td>\n",
       "      <td>2.143449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.044868</td>\n",
       "      <td>0.264934</td>\n",
       "      <td>0.787321</td>\n",
       "      <td>66.574168</td>\n",
       "      <td>3.986228</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.166735</td>\n",
       "      <td>0.155948</td>\n",
       "      <td>0.124077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073157</td>\n",
       "      <td>0.383805</td>\n",
       "      <td>6.434144</td>\n",
       "      <td>1.389110</td>\n",
       "      <td>4.776380</td>\n",
       "      <td>0.391505</td>\n",
       "      <td>4.278387</td>\n",
       "      <td>749.632993</td>\n",
       "      <td>2.038918</td>\n",
       "      <td>1.988746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2</th>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.034109</td>\n",
       "      <td>0.234459</td>\n",
       "      <td>0.592649</td>\n",
       "      <td>71.007963</td>\n",
       "      <td>4.993145</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.143507</td>\n",
       "      <td>0.175888</td>\n",
       "      <td>0.102469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055852</td>\n",
       "      <td>0.363486</td>\n",
       "      <td>5.975985</td>\n",
       "      <td>1.462398</td>\n",
       "      <td>4.145146</td>\n",
       "      <td>0.352022</td>\n",
       "      <td>4.223221</td>\n",
       "      <td>544.593745</td>\n",
       "      <td>2.079512</td>\n",
       "      <td>1.868052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>0.208439</td>\n",
       "      <td>0.548785</td>\n",
       "      <td>66.471393</td>\n",
       "      <td>6.740144</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.193507</td>\n",
       "      <td>0.196872</td>\n",
       "      <td>0.098215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055309</td>\n",
       "      <td>0.277147</td>\n",
       "      <td>4.721589</td>\n",
       "      <td>1.426179</td>\n",
       "      <td>3.206538</td>\n",
       "      <td>0.423588</td>\n",
       "      <td>3.425147</td>\n",
       "      <td>556.090300</td>\n",
       "      <td>2.457044</td>\n",
       "      <td>2.133624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o4</th>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.198182</td>\n",
       "      <td>0.916384</td>\n",
       "      <td>65.927064</td>\n",
       "      <td>6.836099</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.262787</td>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.155372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>3.377818</td>\n",
       "      <td>1.678714</td>\n",
       "      <td>3.279644</td>\n",
       "      <td>0.580139</td>\n",
       "      <td>3.218535</td>\n",
       "      <td>692.225700</td>\n",
       "      <td>2.126584</td>\n",
       "      <td>2.872972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               s0        s1        s2        s3         s4        s5  \\\n",
       "#OTU ID                                                                \n",
       "o0       0.009537  0.052656  0.272251  0.719604  63.118556  5.116637   \n",
       "o1       0.011433  0.044868  0.264934  0.787321  66.574168  3.986228   \n",
       "o2       0.013954  0.034109  0.234459  0.592649  71.007963  4.993145   \n",
       "o3       0.013664  0.034721  0.208439  0.548785  66.471393  6.740144   \n",
       "o4       0.012807  0.048692  0.198182  0.916384  65.927064  6.836099   \n",
       "\n",
       "               s6        s7        s8        s9    ...          s40       s41  \\\n",
       "#OTU ID                                            ...                          \n",
       "o0       0.028943  0.113538  0.134295  0.150017    ...     0.044790  0.332401   \n",
       "o1       0.015542  0.166735  0.155948  0.124077    ...     0.073157  0.383805   \n",
       "o2       0.013265  0.143507  0.175888  0.102469    ...     0.055852  0.363486   \n",
       "o3       0.021424  0.193507  0.196872  0.098215    ...     0.055309  0.277147   \n",
       "o4       0.015092  0.262787  0.222090  0.155372    ...     0.069016  0.284375   \n",
       "\n",
       "              s42       s43       s44       s45       s46         s47  \\\n",
       "#OTU ID                                                                 \n",
       "o0       5.440243  0.899963  3.689245  0.527316  8.582046  866.065909   \n",
       "o1       6.434144  1.389110  4.776380  0.391505  4.278387  749.632993   \n",
       "o2       5.975985  1.462398  4.145146  0.352022  4.223221  544.593745   \n",
       "o3       4.721589  1.426179  3.206538  0.423588  3.425147  556.090300   \n",
       "o4       3.377818  1.678714  3.279644  0.580139  3.218535  692.225700   \n",
       "\n",
       "              s48       s49  \n",
       "#OTU ID                      \n",
       "o0       2.522821  2.143449  \n",
       "o1       2.038918  1.988746  \n",
       "o2       2.079512  1.868052  \n",
       "o3       2.457044  2.133624  \n",
       "o4       2.126584  2.872972  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"~/Desktop/Clemente Lab/CUtIe/data/simulated_data/input_tables/ts_1/txts_cutie/copula_table1_n50_lognorm_3_0.txt\", \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 1)\n",
    "df = df.set_index(list(df)[0])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# fit the model\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "y_pred = clf.fit_predict(df.T)\n",
    "out_df = pd.DataFrame(data = y_pred, index = range(len(list(df)))).reset_index()\n",
    "out_df.to_csv('test.txt', sep = '\\t', header = ['sample','outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0   -1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5   -1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "10   1\n",
      "11  -1\n",
      "12   1\n",
      "13   1\n",
      "14   1\n",
      "15   1\n",
      "16   1\n",
      "17   1\n",
      "18   1\n",
      "19   1\n",
      "20   1\n",
      "21   1\n",
      "22   1\n",
      "23  -1\n",
      "24   1\n",
      "25   1\n",
      "26   1\n",
      "27   1\n",
      "28   1\n",
      "29   1\n",
      "..  ..\n",
      "130  1\n",
      "131  1\n",
      "132  1\n",
      "133  1\n",
      "134  1\n",
      "135  1\n",
      "136  1\n",
      "137  1\n",
      "138  1\n",
      "139  1\n",
      "140  1\n",
      "141  1\n",
      "142  1\n",
      "143 -1\n",
      "144  1\n",
      "145 -1\n",
      "146  1\n",
      "147  1\n",
      "148 -1\n",
      "149  1\n",
      "150  1\n",
      "151  1\n",
      "152 -1\n",
      "153  1\n",
      "154  1\n",
      "155 -1\n",
      "156  1\n",
      "157  1\n",
      "158  1\n",
      "159  1\n",
      "\n",
      "[160 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>37.LLL.58.65</th>\n",
       "      <th>53.LLL.64</th>\n",
       "      <th>66.RM.65</th>\n",
       "      <th>62.LLL.65</th>\n",
       "      <th>54.RM.64</th>\n",
       "      <th>70.LLL.65</th>\n",
       "      <th>68.Buc.65</th>\n",
       "      <th>51.RLL.64</th>\n",
       "      <th>51.Buc.64</th>\n",
       "      <th>45.LLL.64</th>\n",
       "      <th>...</th>\n",
       "      <th>770193.RM.65</th>\n",
       "      <th>770203.1736.B.65</th>\n",
       "      <th>770195.RM.65</th>\n",
       "      <th>770171.Brush.64</th>\n",
       "      <th>770192.LLL.65</th>\n",
       "      <th>770195.LLL.65</th>\n",
       "      <th>31.RM.58.65</th>\n",
       "      <th>770177.RM.65</th>\n",
       "      <th>770188.LLL.65</th>\n",
       "      <th>33.RM.58.65</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o__Cenarchaeales;f__Cenarchaeaceae;g__</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o__Cenarchaeales;f__Cenarchaeaceae;g__Nitrosopumilus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o__Cenarchaeales;f__SAGMA-X;g__</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o__Nitrososphaerales;f__Nitrososphaeraceae;g__Candidatus Nitrososphaera</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Archaea;p__Euryarchaeota;c__Halobacteria;o__Halobacteriales;f__Halobacteriaceae;g__Haloarcula</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    37.LLL.58.65  53.LLL.64  \\\n",
       "#OTU ID                                                                       \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0        0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...           0.0        0.0   \n",
       "\n",
       "                                                    66.RM.65  62.LLL.65  \\\n",
       "#OTU ID                                                                   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...       0.0        0.0   \n",
       "\n",
       "                                                    54.RM.64  70.LLL.65  \\\n",
       "#OTU ID                                                                   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...       0.0        0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...       0.0        0.0   \n",
       "\n",
       "                                                    68.Buc.65  51.RLL.64  \\\n",
       "#OTU ID                                                                    \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...        0.0        0.0   \n",
       "\n",
       "                                                    51.Buc.64  45.LLL.64  \\\n",
       "#OTU ID                                                                    \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...        0.0        0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...        0.0        0.0   \n",
       "\n",
       "                                                       ...       770193.RM.65  \\\n",
       "#OTU ID                                                ...                      \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...     ...                0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...     ...                0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...     ...                0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...     ...                0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...     ...                0.0   \n",
       "\n",
       "                                                    770203.1736.B.65  \\\n",
       "#OTU ID                                                                \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...               0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...               0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...               0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...               0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...               0.0   \n",
       "\n",
       "                                                    770195.RM.65  \\\n",
       "#OTU ID                                                            \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...           0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...           0.0   \n",
       "\n",
       "                                                    770171.Brush.64  \\\n",
       "#OTU ID                                                               \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...              0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...              0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...              0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...              0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...              0.0   \n",
       "\n",
       "                                                    770192.LLL.65  \\\n",
       "#OTU ID                                                             \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...            0.0   \n",
       "\n",
       "                                                    770195.LLL.65  \\\n",
       "#OTU ID                                                             \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...            0.0   \n",
       "\n",
       "                                                    31.RM.58.65  770177.RM.65  \\\n",
       "#OTU ID                                                                         \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...          0.0           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...          0.0           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...          0.0           0.0   \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...          0.0           0.0   \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...          0.0           0.0   \n",
       "\n",
       "                                                    770188.LLL.65  33.RM.58.65  \n",
       "#OTU ID                                                                         \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0          0.0  \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0          0.0  \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0          0.0  \n",
       "k__Archaea;p__Crenarchaeota;c__Thaumarchaeota;o...            0.0          0.0  \n",
       "k__Archaea;p__Euryarchaeota;c__Halobacteria;o__...            0.0          0.0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"~/Desktop/Clemente Lab/CUtIe/data/pre_sparcc_MSQ/otu_table.MSQ34_L6.txt\", \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 1)\n",
    "df = df.set_index(list(df)[0])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s40</th>\n",
       "      <th>s41</th>\n",
       "      <th>s42</th>\n",
       "      <th>s43</th>\n",
       "      <th>s44</th>\n",
       "      <th>s45</th>\n",
       "      <th>s46</th>\n",
       "      <th>s47</th>\n",
       "      <th>s48</th>\n",
       "      <th>s49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o0</th>\n",
       "      <td>198.771721</td>\n",
       "      <td>3.152505</td>\n",
       "      <td>5.300961</td>\n",
       "      <td>1.040519</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>119.083014</td>\n",
       "      <td>2.759216</td>\n",
       "      <td>6.296837</td>\n",
       "      <td>24.684921</td>\n",
       "      <td>...</td>\n",
       "      <td>2.691605</td>\n",
       "      <td>6.120082</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.078959</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.623511</td>\n",
       "      <td>1.586171</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.361753</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>3.321683</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>14.547536</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>5.572708</td>\n",
       "      <td>5.507811</td>\n",
       "      <td>76.736404</td>\n",
       "      <td>252.421404</td>\n",
       "      <td>0.495792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998561</td>\n",
       "      <td>6.977364</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.097206</td>\n",
       "      <td>113.208039</td>\n",
       "      <td>23.398924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2</th>\n",
       "      <td>18.844365</td>\n",
       "      <td>26.817121</td>\n",
       "      <td>0.281691</td>\n",
       "      <td>2.765379</td>\n",
       "      <td>1.148441</td>\n",
       "      <td>301.224127</td>\n",
       "      <td>0.709311</td>\n",
       "      <td>0.525458</td>\n",
       "      <td>2.255277</td>\n",
       "      <td>0.736817</td>\n",
       "      <td>...</td>\n",
       "      <td>11.638839</td>\n",
       "      <td>0.542997</td>\n",
       "      <td>34.513298</td>\n",
       "      <td>96.122554</td>\n",
       "      <td>1.770100</td>\n",
       "      <td>8.301042</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.120505</td>\n",
       "      <td>764.570210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>831.041387</td>\n",
       "      <td>0.495272</td>\n",
       "      <td>1.369084</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>2.127379</td>\n",
       "      <td>146.806717</td>\n",
       "      <td>30.245363</td>\n",
       "      <td>0.639396</td>\n",
       "      <td>...</td>\n",
       "      <td>3.613371</td>\n",
       "      <td>4.198004</td>\n",
       "      <td>209.392156</td>\n",
       "      <td>0.472891</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.404060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o4</th>\n",
       "      <td>271.150487</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>1.982106</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>0.784715</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>8.119664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>12.508647</td>\n",
       "      <td>1.098576</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>2.347198</td>\n",
       "      <td>16.698330</td>\n",
       "      <td>2.672506</td>\n",
       "      <td>22.992043</td>\n",
       "      <td>2.639005</td>\n",
       "      <td>2.675739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s0         s1         s2        s3        s4          s5  \\\n",
       "#OTU ID                                                                     \n",
       "o0       198.771721   3.152505   5.300961  1.040519  0.010064    0.007758   \n",
       "o1         3.321683   0.902373  14.547536  0.693617  0.005882    5.572708   \n",
       "o2        18.844365  26.817121   0.281691  2.765379  1.148441  301.224127   \n",
       "o3       831.041387   0.495272   1.369084  0.170521  0.056409    0.097589   \n",
       "o4       271.150487   0.352624   1.982106  0.068054  0.784715    0.568776   \n",
       "\n",
       "                 s6          s7          s8         s9     ...            s40  \\\n",
       "#OTU ID                                                    ...                  \n",
       "o0       119.083014    2.759216    6.296837  24.684921     ...       2.691605   \n",
       "o1         5.507811   76.736404  252.421404   0.495792     ...       0.998561   \n",
       "o2         0.709311    0.525458    2.255277   0.736817     ...      11.638839   \n",
       "o3         2.127379  146.806717   30.245363   0.639396     ...       3.613371   \n",
       "o4         0.026448    0.077726    0.005434   8.119664     ...       0.000547   \n",
       "\n",
       "               s41         s42        s43       s44        s45       s46  \\\n",
       "#OTU ID                                                                    \n",
       "o0        6.120082    0.051975   0.078959  0.092821   0.623511  1.586171   \n",
       "o1        6.977364    0.006615   0.272016  0.057573   0.026255  0.002019   \n",
       "o2        0.542997   34.513298  96.122554  1.770100   8.301042  0.004804   \n",
       "o3        4.198004  209.392156   0.472891  0.138500   0.084360  0.065644   \n",
       "o4       12.508647    1.098576   0.027195  2.347198  16.698330  2.672506   \n",
       "\n",
       "               s47         s48         s49  \n",
       "#OTU ID                                     \n",
       "o0        0.015250    0.361753    0.037288  \n",
       "o1        0.097206  113.208039   23.398924  \n",
       "o2        0.001146    0.120505  764.570210  \n",
       "o3        0.027368    0.020933    0.404060  \n",
       "o4       22.992043    2.639005    2.675739  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/KevinBu/Desktop/Clemente Lab/CUtIe/data/simulated_data/input_tables/ts_1/txts_cutie/copula_table1_n50_lognorm_3_0_indep.txt\", \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 1)\n",
    "df = df.set_index(list(df)[0])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>#OTU ID</th>\n",
       "      <th>o0</th>\n",
       "      <th>o1</th>\n",
       "      <th>o2</th>\n",
       "      <th>o3</th>\n",
       "      <th>o4</th>\n",
       "      <th>o5</th>\n",
       "      <th>o6</th>\n",
       "      <th>o7</th>\n",
       "      <th>o8</th>\n",
       "      <th>o9</th>\n",
       "      <th>...</th>\n",
       "      <th>o490</th>\n",
       "      <th>o491</th>\n",
       "      <th>o492</th>\n",
       "      <th>o493</th>\n",
       "      <th>o494</th>\n",
       "      <th>o495</th>\n",
       "      <th>o496</th>\n",
       "      <th>o497</th>\n",
       "      <th>o498</th>\n",
       "      <th>o499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s0</th>\n",
       "      <td>198.771721</td>\n",
       "      <td>3.321683</td>\n",
       "      <td>18.844365</td>\n",
       "      <td>831.041387</td>\n",
       "      <td>271.150487</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>17.292368</td>\n",
       "      <td>0.635037</td>\n",
       "      <td>0.733699</td>\n",
       "      <td>3.427378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>0.349997</td>\n",
       "      <td>27.135776</td>\n",
       "      <td>49.110159</td>\n",
       "      <td>3257.359438</td>\n",
       "      <td>0.801096</td>\n",
       "      <td>0.138670</td>\n",
       "      <td>0.213803</td>\n",
       "      <td>0.047164</td>\n",
       "      <td>0.791707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>3.152505</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>26.817121</td>\n",
       "      <td>0.495272</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>0.174854</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>49.614554</td>\n",
       "      <td>...</td>\n",
       "      <td>3.755039</td>\n",
       "      <td>1.709804</td>\n",
       "      <td>0.090875</td>\n",
       "      <td>2.059293</td>\n",
       "      <td>2.380621</td>\n",
       "      <td>3.450822</td>\n",
       "      <td>0.551454</td>\n",
       "      <td>1.326544</td>\n",
       "      <td>0.031974</td>\n",
       "      <td>0.341522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>5.300961</td>\n",
       "      <td>14.547536</td>\n",
       "      <td>0.281691</td>\n",
       "      <td>1.369084</td>\n",
       "      <td>1.982106</td>\n",
       "      <td>1.830227</td>\n",
       "      <td>5.064831</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.862455</td>\n",
       "      <td>2.048486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049959</td>\n",
       "      <td>0.108565</td>\n",
       "      <td>0.183325</td>\n",
       "      <td>4.170743</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>52.229792</td>\n",
       "      <td>0.487780</td>\n",
       "      <td>0.476932</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.709868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>1.040519</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>2.765379</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>5.180929</td>\n",
       "      <td>1.344473</td>\n",
       "      <td>1.806774</td>\n",
       "      <td>23.976682</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>...</td>\n",
       "      <td>56.140980</td>\n",
       "      <td>0.108630</td>\n",
       "      <td>51.697685</td>\n",
       "      <td>0.378942</td>\n",
       "      <td>1.810285</td>\n",
       "      <td>1.340781</td>\n",
       "      <td>66.991802</td>\n",
       "      <td>1.608499</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>0.019587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>1.148441</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.784715</td>\n",
       "      <td>0.121047</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>8.254485</td>\n",
       "      <td>16.239320</td>\n",
       "      <td>...</td>\n",
       "      <td>1.525667</td>\n",
       "      <td>4.139044</td>\n",
       "      <td>261.318149</td>\n",
       "      <td>69.893222</td>\n",
       "      <td>0.403234</td>\n",
       "      <td>19.473184</td>\n",
       "      <td>5.798228</td>\n",
       "      <td>30.239960</td>\n",
       "      <td>7.499600</td>\n",
       "      <td>0.053799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "#OTU ID          o0         o1         o2          o3          o4        o5  \\\n",
       "s0       198.771721   3.321683  18.844365  831.041387  271.150487  0.053299   \n",
       "s1         3.152505   0.902373  26.817121    0.495272    0.352624  0.174854   \n",
       "s2         5.300961  14.547536   0.281691    1.369084    1.982106  1.830227   \n",
       "s3         1.040519   0.693617   2.765379    0.170521    0.068054  5.180929   \n",
       "s4         0.010064   0.005882   1.148441    0.056409    0.784715  0.121047   \n",
       "\n",
       "#OTU ID         o6        o7         o8         o9    ...          o490  \\\n",
       "s0       17.292368  0.635037   0.733699   3.427378    ...      0.045511   \n",
       "s1        0.007462  0.009065   0.029087  49.614554    ...      3.755039   \n",
       "s2        5.064831  0.004278   0.862455   2.048486    ...      0.049959   \n",
       "s3        1.344473  1.806774  23.976682   0.046528    ...     56.140980   \n",
       "s4        0.099028  0.236328   8.254485  16.239320    ...      1.525667   \n",
       "\n",
       "#OTU ID      o491        o492       o493         o494       o495       o496  \\\n",
       "s0       0.349997   27.135776  49.110159  3257.359438   0.801096   0.138670   \n",
       "s1       1.709804    0.090875   2.059293     2.380621   3.450822   0.551454   \n",
       "s2       0.108565    0.183325   4.170743     0.001543  52.229792   0.487780   \n",
       "s3       0.108630   51.697685   0.378942     1.810285   1.340781  66.991802   \n",
       "s4       4.139044  261.318149  69.893222     0.403234  19.473184   5.798228   \n",
       "\n",
       "#OTU ID       o497      o498      o499  \n",
       "s0        0.213803  0.047164  0.791707  \n",
       "s1        1.326544  0.031974  0.341522  \n",
       "s2        0.476932  0.039241  0.709868  \n",
       "s3        1.608499  0.032526  0.019587  \n",
       "s4       30.239960  7.499600  0.053799  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df = df.dropna(how = 'any', axis = 0)\n",
    "#df = df.set_index(list(df)[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/KevinBu/Desktop/Clemente Lab/CUtIe/data/MINE/WHOfix.txt\", \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 0)\n",
    "df = df.set_index(list(df)[0])\n",
    " \n",
    "n_samp = 202\n",
    "startcol = 3\n",
    "endcol = 357\n",
    "df = df.iloc[:,(startcol-1):(endcol-(startcol-1))]\n",
    "df = df.dropna(how = 'any', axis = 0)\n",
    "np.random.seed(42)\n",
    "# fit the model\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "try:\n",
    "    y_pred = clf.fit_predict(df)\n",
    "except:\n",
    "    y_pred = np.ones(n_samp)\n",
    "\n",
    "#.shape[0] gives number of rows\n",
    "out_df = pd.DataFrame(data = y_pred, index = range(n_samp)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>...</th>\n",
       "      <th>United States of America</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>Vanuatu</th>\n",
       "      <th>Venezuela</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zambia</th>\n",
       "      <th>Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adolescent fertility rate (%)</th>\n",
       "      <td>151.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult literacy rate (%)</th>\n",
       "      <td>28.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>69.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>89.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross national income per capita (PPP international $)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>15130.0</td>\n",
       "      <td>11670.0</td>\n",
       "      <td>4950.0</td>\n",
       "      <td>33940.0</td>\n",
       "      <td>36040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44070.0</td>\n",
       "      <td>9940.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>10970.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net primary school enrolment ratio female (%)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net primary school enrolment ratio male (%)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                                             Afghanistan  Albania  \\\n",
       "Adolescent fertility rate (%)                             151.0     27.0   \n",
       "Adult literacy rate (%)                                    28.0     98.7   \n",
       "Gross national income per capita (PPP internati...          NaN   6000.0   \n",
       "Net primary school enrolment ratio female (%)               NaN     93.0   \n",
       "Net primary school enrolment ratio male (%)                 NaN     94.0   \n",
       "\n",
       "Country                                             Algeria  Andorra  Angola  \\\n",
       "Adolescent fertility rate (%)                           6.0      NaN   146.0   \n",
       "Adult literacy rate (%)                                69.9      NaN    67.4   \n",
       "Gross national income per capita (PPP internati...   5940.0      NaN  3890.0   \n",
       "Net primary school enrolment ratio female (%)          94.0     83.0    49.0   \n",
       "Net primary school enrolment ratio male (%)            96.0     83.0    51.0   \n",
       "\n",
       "Country                                             Antigua and Barbuda  \\\n",
       "Adolescent fertility rate (%)                                       NaN   \n",
       "Adult literacy rate (%)                                             NaN   \n",
       "Gross national income per capita (PPP internati...              15130.0   \n",
       "Net primary school enrolment ratio female (%)                       NaN   \n",
       "Net primary school enrolment ratio male (%)                         NaN   \n",
       "\n",
       "Country                                             Argentina  Armenia  \\\n",
       "Adolescent fertility rate (%)                            62.0     30.0   \n",
       "Adult literacy rate (%)                                  97.2     99.4   \n",
       "Gross national income per capita (PPP internati...    11670.0   4950.0   \n",
       "Net primary school enrolment ratio female (%)            98.0     84.0   \n",
       "Net primary school enrolment ratio male (%)              99.0     80.0   \n",
       "\n",
       "Country                                             Australia  Austria  \\\n",
       "Adolescent fertility rate (%)                            16.0     14.0   \n",
       "Adult literacy rate (%)                                   NaN      NaN   \n",
       "Gross national income per capita (PPP internati...    33940.0  36040.0   \n",
       "Net primary school enrolment ratio female (%)            97.0     98.0   \n",
       "Net primary school enrolment ratio male (%)              96.0     97.0   \n",
       "\n",
       "Country                                               ...     \\\n",
       "Adolescent fertility rate (%)                         ...      \n",
       "Adult literacy rate (%)                               ...      \n",
       "Gross national income per capita (PPP internati...    ...      \n",
       "Net primary school enrolment ratio female (%)         ...      \n",
       "Net primary school enrolment ratio male (%)           ...      \n",
       "\n",
       "Country                                             United States of America  \\\n",
       "Adolescent fertility rate (%)                                           43.0   \n",
       "Adult literacy rate (%)                                                  NaN   \n",
       "Gross national income per capita (PPP internati...                   44070.0   \n",
       "Net primary school enrolment ratio female (%)                           93.0   \n",
       "Net primary school enrolment ratio male (%)                             91.0   \n",
       "\n",
       "Country                                             Uruguay  Uzbekistan  \\\n",
       "Adolescent fertility rate (%)                          64.0        40.0   \n",
       "Adult literacy rate (%)                                96.8         NaN   \n",
       "Gross national income per capita (PPP internati...   9940.0      2190.0   \n",
       "Net primary school enrolment ratio female (%)         100.0        78.0   \n",
       "Net primary school enrolment ratio male (%)           100.0        79.0   \n",
       "\n",
       "Country                                             Vanuatu  Venezuela  \\\n",
       "Adolescent fertility rate (%)                          92.0       81.0   \n",
       "Adult literacy rate (%)                                75.5       93.0   \n",
       "Gross national income per capita (PPP internati...   3480.0    10970.0   \n",
       "Net primary school enrolment ratio female (%)          86.0       91.0   \n",
       "Net primary school enrolment ratio male (%)            88.0       91.0   \n",
       "\n",
       "Country                                             Vietnam  \\\n",
       "Adolescent fertility rate (%)                          25.0   \n",
       "Adult literacy rate (%)                                90.3   \n",
       "Gross national income per capita (PPP internati...   2310.0   \n",
       "Net primary school enrolment ratio female (%)          91.0   \n",
       "Net primary school enrolment ratio male (%)            96.0   \n",
       "\n",
       "Country                                             West Bank and Gaza  \\\n",
       "Adolescent fertility rate (%)                                      NaN   \n",
       "Adult literacy rate (%)                                            NaN   \n",
       "Gross national income per capita (PPP internati...                 NaN   \n",
       "Net primary school enrolment ratio female (%)                      NaN   \n",
       "Net primary school enrolment ratio male (%)                        NaN   \n",
       "\n",
       "Country                                              Yemen  Zambia  Zimbabwe  \n",
       "Adolescent fertility rate (%)                         83.0   161.0     101.0  \n",
       "Adult literacy rate (%)                               54.1    68.0      89.5  \n",
       "Gross national income per capita (PPP internati...  2090.0  1140.0       NaN  \n",
       "Net primary school enrolment ratio female (%)         65.0    94.0      88.0  \n",
       "Net primary school enrolment ratio male (%)           85.0    90.0      87.0  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "#df = df.dropna(how = 'any', axis = 0)\n",
    "#df = df.set_index(list(df)[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(353, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-61d438b241bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/neighbors/lof.pyc\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \"\"\"\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/neighbors/lof.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"contamination must be in (0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \"\"\"\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    437\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 439\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(353, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print len(df.columns)\n",
    "np.random.seed(42)\n",
    "#df.T.head()\n",
    "# fit the model\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "y_pred = clf.fit_predict(df.T)\n",
    "print np.array(range(len(y_pred)))[y_pred == -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895955882353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.mean((df == 0).astype(int).sum(axis=1).values)/160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000    159\n",
      "0.000073      1\n",
      "Name: k__Bacteria;p__Actinobacteria;c__Actinobacteria;o__Actinomycetales;f__Cellulomonadaceae;g__Demequina, dtype: int64\n",
      "0.000000    154\n",
      "0.002527      1\n",
      "0.003282      1\n",
      "0.007964      1\n",
      "0.000165      1\n",
      "0.000254      1\n",
      "0.000067      1\n",
      "Name: k__Bacteria;p__Acidobacteria;c__Solibacteres;o__Solibacterales;f__;g__, dtype: int64\n",
      "(0.018567692401223926, 0.81572772373866953)\n",
      "(0.01850589323428636, 0.81690379921529366)\n",
      "SpearmanrResult(correlation=0.39907460407713852, pvalue=1.7211038181258791e-07)\n",
      "SpearmanrResult(correlation=nan, pvalue=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "//anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "//anaconda/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "//anaconda/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "//anaconda/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# 58, 255\n",
    "x = df.ix[45]\n",
    "y = df.ix[21]\n",
    "print x.value_counts()\n",
    "print y.value_counts()\n",
    "print scipy.stats.pearsonr(x,y)\n",
    "print scipy.stats.pearsonr(x.drop('51.RLL.64'),y.drop('51.RLL.64'))\n",
    "print scipy.stats.spearmanr(x,y)\n",
    "print scipy.stats.spearmanr(x.drop('131016.N.RL.64'),y.drop('131016.N.RL.64'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.LLL.58.65          0.000000\n",
       "53.LLL.64             0.000000\n",
       "66.RM.65              0.000000\n",
       "62.LLL.65             0.000000\n",
       "54.RM.64              0.000000\n",
       "70.LLL.65             0.000000\n",
       "68.Buc.65             0.000000\n",
       "51.RLL.64             0.000000\n",
       "51.Buc.64             0.000000\n",
       "45.LLL.64             0.000000\n",
       "55.LLL.64             0.000000\n",
       "38.RM.64              0.000000\n",
       "50.BUC.64             0.000000\n",
       "68.LLL.65             0.000000\n",
       "770179.RM.65          0.000000\n",
       "770190.B.65           0.000000\n",
       "131016.N.RL.64        0.000073\n",
       "770195.B.65           0.000000\n",
       "770171.RM.64          0.000000\n",
       "57.RM.64              0.000000\n",
       "770187.B.65           0.000000\n",
       "110502BC.N.1.RL.64    0.000000\n",
       "770186.LLL.65         0.000000\n",
       "770172.LLL.64         0.000000\n",
       "770172.RM.64          0.000000\n",
       "770181.B.65           0.000000\n",
       "101018WG.N.1.RL.64    0.000000\n",
       "68.RML.65             0.000000\n",
       "50.RM.64              0.000000\n",
       "770180.B.65           0.000000\n",
       "                        ...   \n",
       "770179.B.65           0.000000\n",
       "770192.B.65           0.000000\n",
       "770176.Brush.64       0.000000\n",
       "42.Buc.64             0.000000\n",
       "770191.RM.65          0.000000\n",
       "770183.LLL.65         0.000000\n",
       "770180.RLL.65         0.000000\n",
       "770177.B.65           0.000000\n",
       "770186.B.65           0.000000\n",
       "38.LLL.64             0.000000\n",
       "770180.RM.65          0.000000\n",
       "770185.LLL.65         0.000000\n",
       "770175.Brush.64       0.000000\n",
       "29.RM.58.65           0.000000\n",
       "770178.RM.65          0.000000\n",
       "36.BUC.64             0.000000\n",
       "770173.Brush.64       0.000000\n",
       "770183.RM.65          0.000000\n",
       "770181.LM.65          0.000000\n",
       "770178.LLL.65         0.000000\n",
       "770193.RM.65          0.000000\n",
       "770203.1736.B.65      0.000000\n",
       "770195.RM.65          0.000000\n",
       "770171.Brush.64       0.000000\n",
       "770192.LLL.65         0.000000\n",
       "770195.LLL.65         0.000000\n",
       "31.RM.58.65           0.000000\n",
       "770177.RM.65          0.000000\n",
       "770188.LLL.65         0.000000\n",
       "33.RM.58.65           0.000000\n",
       "Name: k__Bacteria;p__Actinobacteria;c__Actinobacteria;o__Actinomycetales;f__Cellulomonadaceae;g__Demequina, Length: 160, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    159\n",
       "0.004326      1\n",
       "Name: k__Bacteria;p__Firmicutes;c__Bacilli;o__Bacillales;f__Sporolactobacillaceae;g__, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryID</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Adolescent fertility rate (%)</th>\n",
       "      <th>Adult literacy rate (%)</th>\n",
       "      <th>Gross national income per capita (PPP international $)</th>\n",
       "      <th>Net primary school enrolment ratio female (%)</th>\n",
       "      <th>Net primary school enrolment ratio male (%)</th>\n",
       "      <th>Population (in thousands) total</th>\n",
       "      <th>Population annual growth rate (%)</th>\n",
       "      <th>Population in urban areas (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_CO2_emissions</th>\n",
       "      <th>Total_income</th>\n",
       "      <th>Total_reserves</th>\n",
       "      <th>Trade_balance_goods_and_services</th>\n",
       "      <th>Under_five_mortality_from_CME</th>\n",
       "      <th>Under_five_mortality_from_IHME</th>\n",
       "      <th>Under_five_mortality_rate</th>\n",
       "      <th>Urban_population</th>\n",
       "      <th>Urban_population_growth</th>\n",
       "      <th>Urban_population_pct_of_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26088.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.00</td>\n",
       "      <td>231.9</td>\n",
       "      <td>257.00</td>\n",
       "      <td>5740436.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3499.12</td>\n",
       "      <td>4.790000e+09</td>\n",
       "      <td>78.14</td>\n",
       "      <td>-2.040000e+09</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.47</td>\n",
       "      <td>1431793.9</td>\n",
       "      <td>2.21</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33351.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137535.56</td>\n",
       "      <td>6.970000e+10</td>\n",
       "      <td>351.36</td>\n",
       "      <td>4.700000e+09</td>\n",
       "      <td>40.00</td>\n",
       "      <td>31.2</td>\n",
       "      <td>40.00</td>\n",
       "      <td>20800000.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>16557.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8991.46</td>\n",
       "      <td>1.490000e+10</td>\n",
       "      <td>27.13</td>\n",
       "      <td>9.140000e+09</td>\n",
       "      <td>164.10</td>\n",
       "      <td>242.5</td>\n",
       "      <td>164.10</td>\n",
       "      <td>8578749.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CountryID  Continent  Adolescent fertility rate (%)  \\\n",
       "Country                                                            \n",
       "Afghanistan          1          1                          151.0   \n",
       "Albania              2          2                           27.0   \n",
       "Algeria              3          3                            6.0   \n",
       "Andorra              4          2                            NaN   \n",
       "Angola               5          3                          146.0   \n",
       "\n",
       "             Adult literacy rate (%)  \\\n",
       "Country                                \n",
       "Afghanistan                     28.0   \n",
       "Albania                         98.7   \n",
       "Algeria                         69.9   \n",
       "Andorra                          NaN   \n",
       "Angola                          67.4   \n",
       "\n",
       "             Gross national income per capita (PPP international $)  \\\n",
       "Country                                                               \n",
       "Afghanistan                                                NaN        \n",
       "Albania                                                 6000.0        \n",
       "Algeria                                                 5940.0        \n",
       "Andorra                                                    NaN        \n",
       "Angola                                                  3890.0        \n",
       "\n",
       "             Net primary school enrolment ratio female (%)  \\\n",
       "Country                                                      \n",
       "Afghanistan                                            NaN   \n",
       "Albania                                               93.0   \n",
       "Algeria                                               94.0   \n",
       "Andorra                                               83.0   \n",
       "Angola                                                49.0   \n",
       "\n",
       "             Net primary school enrolment ratio male (%)  \\\n",
       "Country                                                    \n",
       "Afghanistan                                          NaN   \n",
       "Albania                                             94.0   \n",
       "Algeria                                             96.0   \n",
       "Andorra                                             83.0   \n",
       "Angola                                              51.0   \n",
       "\n",
       "             Population (in thousands) total  \\\n",
       "Country                                        \n",
       "Afghanistan                          26088.0   \n",
       "Albania                               3172.0   \n",
       "Algeria                              33351.0   \n",
       "Andorra                                 74.0   \n",
       "Angola                               16557.0   \n",
       "\n",
       "             Population annual growth rate (%)  Population in urban areas (%)  \\\n",
       "Country                                                                         \n",
       "Afghanistan                                4.0                           23.0   \n",
       "Albania                                    0.6                           46.0   \n",
       "Algeria                                    1.5                           64.0   \n",
       "Andorra                                    1.0                           93.0   \n",
       "Angola                                     2.8                           54.0   \n",
       "\n",
       "                         ...                Total_CO2_emissions  Total_income  \\\n",
       "Country                  ...                                                    \n",
       "Afghanistan              ...                             692.50           NaN   \n",
       "Albania                  ...                            3499.12  4.790000e+09   \n",
       "Algeria                  ...                          137535.56  6.970000e+10   \n",
       "Andorra                  ...                                NaN           NaN   \n",
       "Angola                   ...                            8991.46  1.490000e+10   \n",
       "\n",
       "             Total_reserves  Trade_balance_goods_and_services  \\\n",
       "Country                                                         \n",
       "Afghanistan             NaN                               NaN   \n",
       "Albania               78.14                     -2.040000e+09   \n",
       "Algeria              351.36                      4.700000e+09   \n",
       "Andorra                 NaN                               NaN   \n",
       "Angola                27.13                      9.140000e+09   \n",
       "\n",
       "             Under_five_mortality_from_CME  Under_five_mortality_from_IHME  \\\n",
       "Country                                                                      \n",
       "Afghanistan                         257.00                           231.9   \n",
       "Albania                              18.47                            15.5   \n",
       "Algeria                              40.00                            31.2   \n",
       "Andorra                                NaN                             NaN   \n",
       "Angola                              164.10                           242.5   \n",
       "\n",
       "             Under_five_mortality_rate  Urban_population  \\\n",
       "Country                                                    \n",
       "Afghanistan                     257.00         5740436.0   \n",
       "Albania                          18.47         1431793.9   \n",
       "Algeria                          40.00        20800000.0   \n",
       "Andorra                            NaN               NaN   \n",
       "Angola                          164.10         8578749.0   \n",
       "\n",
       "             Urban_population_growth  Urban_population_pct_of_total  \n",
       "Country                                                              \n",
       "Afghanistan                     5.44                           22.9  \n",
       "Albania                         2.21                           45.4  \n",
       "Algeria                         2.61                           63.3  \n",
       "Andorra                          NaN                            NaN  \n",
       "Angola                          4.14                           53.3  \n",
       "\n",
       "[5 rows x 356 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('~/Desktop/Clemente Lab/CUtIe/data/MINE/WHOfix.txt', \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 0)\n",
    "df = df.set_index(list(df)[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.values[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aid_given'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)[168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prostate_cancer_new_cases_per_100_000_men Oil_consumption\n",
      "(0.29329927004084355, 0.01866603875487579)\n",
      "SpearmanrResult(correlation=0.017788868797445723, pvalue=0.88904153579114742)\n",
      "[   5.6    36.8    76.     71.4     7.5     0.3    19.     74.2    53.2\n",
      "   14.8    78.2    40.6     1.7    48.3    38.1    39.3    35.9     4.4\n",
      "   84.4    59.3    60.5    26.2    10.46   34.     81.      4.6     7.\n",
      "    5.4    56.3    40.5    12.6     9.8     7.6     9.6    32.3     8.7\n",
      "   29.9    56.7   100.9    81.8     5.6    46.     18.6    24.1    46.8\n",
      "    9.5    16.8    12.8     8.5    13.8    30.5    42.9    35.9    90.9\n",
      "   77.3     4.5     8.      2.5    14.5    10.4    52.2   124.8     2.4\n",
      "   42.4 ]\n",
      "[   251.35    421.42    885.7     294.37    108.19     95.72    142.86\n",
      "    815.43   2047.53    109.22   2247.32    256.31   6984.12    224.62\n",
      "    211.15    194.97    167.68    628.64    232.76   1960.21   2604.8\n",
      "    434.29    285.17    163.41     20.82   2569.04   1231.8    1577.94\n",
      "    195.61   1819.03   5358.08    207.11   2307.64    302.31     58.33\n",
      "    476.91   1973.95   1070.48    154.8     211.84    312.09    165.27\n",
      "    313.84    479.2     330.79     64.99    222.92   2601.41   1890.57\n",
      "    793.78     80.8     525.8    1618.9     314.71    262.42    928.6\n",
      "    649.55    100.16    294.05    376.49   1802.2   20802.18    114.49\n",
      "    573.9 ]\n"
     ]
    }
   ],
   "source": [
    "# 58, 255\n",
    "print list(df)[326], list(df)[303]\n",
    "\n",
    "x = df.ix[:,326]\n",
    "y = df.ix[:,303]\n",
    "#print x.value_counts()\n",
    "#print y.value_counts()\n",
    "stacked = np.stack([x,y],0)\n",
    "stacked = stacked[:,np.all(~np.isnan(stacked), axis = 0)]\n",
    "x = stacked[0]\n",
    "y = stacked[1]\n",
    "print scipy.stats.pearsonr(x,y)\n",
    "#print scipy.stats.pearsonr(x.drop('51.RLL.64'),y.drop('51.RLL.64'))\n",
    "print scipy.stats.spearmanr(x,y)\n",
    "#print scipy.stats.spearmanr(x.drop('131016.N.RL.64'),y.drop('131016.N.RL.64'))\n",
    "\n",
    "print x\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glutamic_acid</th>\n",
       "      <th>glycine</th>\n",
       "      <th>alanine</th>\n",
       "      <th>succinic_acid</th>\n",
       "      <th>aspartic_acid</th>\n",
       "      <th>glutamine</th>\n",
       "      <th>serine</th>\n",
       "      <th>methionine</th>\n",
       "      <th>urea</th>\n",
       "      <th>sucrose</th>\n",
       "      <th>...</th>\n",
       "      <th>myristic_acid</th>\n",
       "      <th>1_5_anhydroglucitol</th>\n",
       "      <th>azelaic_acid</th>\n",
       "      <th>behenic_acid</th>\n",
       "      <th>palmitoleic_acid</th>\n",
       "      <th>dihydroabietic_acid</th>\n",
       "      <th>pentadecanoic_acid</th>\n",
       "      <th>threitol</th>\n",
       "      <th>octadecanol</th>\n",
       "      <th>1_monostearin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100716FG.C.1.RL</th>\n",
       "      <td>60088.12140</td>\n",
       "      <td>8.110014e+05</td>\n",
       "      <td>144276.0444</td>\n",
       "      <td>30070.95780</td>\n",
       "      <td>67135.16160</td>\n",
       "      <td>386941.680600</td>\n",
       "      <td>48898.92780</td>\n",
       "      <td>27381.24780</td>\n",
       "      <td>6.677151e+06</td>\n",
       "      <td>6939.451800</td>\n",
       "      <td>...</td>\n",
       "      <td>3.999599e+05</td>\n",
       "      <td>86877.6330</td>\n",
       "      <td>47231.30760</td>\n",
       "      <td>26197.77540</td>\n",
       "      <td>131688.20160</td>\n",
       "      <td>203772.429600</td>\n",
       "      <td>4.797905e+05</td>\n",
       "      <td>5218.037400</td>\n",
       "      <td>36795.232800</td>\n",
       "      <td>42228.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100804MB.C.1.RL</th>\n",
       "      <td>120075.13440</td>\n",
       "      <td>1.931722e+06</td>\n",
       "      <td>197367.0879</td>\n",
       "      <td>84091.07970</td>\n",
       "      <td>98779.75800</td>\n",
       "      <td>950017.529700</td>\n",
       "      <td>44450.89110</td>\n",
       "      <td>18537.24030</td>\n",
       "      <td>8.246570e+06</td>\n",
       "      <td>21936.803400</td>\n",
       "      <td>...</td>\n",
       "      <td>7.797187e+05</td>\n",
       "      <td>330270.7623</td>\n",
       "      <td>43232.17980</td>\n",
       "      <td>73379.24880</td>\n",
       "      <td>273568.61550</td>\n",
       "      <td>677860.053600</td>\n",
       "      <td>9.592541e+05</td>\n",
       "      <td>18408.954900</td>\n",
       "      <td>127579.830300</td>\n",
       "      <td>91339.204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100907LG.C.1.RL</th>\n",
       "      <td>19712.98000</td>\n",
       "      <td>1.569294e+05</td>\n",
       "      <td>51957.7830</td>\n",
       "      <td>213252.20150</td>\n",
       "      <td>38933.13550</td>\n",
       "      <td>693544.878500</td>\n",
       "      <td>28231.80350</td>\n",
       "      <td>22810.73400</td>\n",
       "      <td>1.427332e+07</td>\n",
       "      <td>17108.050500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.918822e+05</td>\n",
       "      <td>648345.8315</td>\n",
       "      <td>126867.10700</td>\n",
       "      <td>57449.25600</td>\n",
       "      <td>281191.57900</td>\n",
       "      <td>548020.844000</td>\n",
       "      <td>8.000654e+05</td>\n",
       "      <td>23373.962000</td>\n",
       "      <td>47874.380000</td>\n",
       "      <td>76528.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101007PC.C.1.RL</th>\n",
       "      <td>17490.17800</td>\n",
       "      <td>1.268707e+06</td>\n",
       "      <td>90846.0422</td>\n",
       "      <td>297384.46770</td>\n",
       "      <td>42182.19400</td>\n",
       "      <td>241261.573000</td>\n",
       "      <td>26338.15040</td>\n",
       "      <td>47480.68910</td>\n",
       "      <td>1.038325e+07</td>\n",
       "      <td>10288.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.184599e+06</td>\n",
       "      <td>910055.1147</td>\n",
       "      <td>8282.11370</td>\n",
       "      <td>22891.55650</td>\n",
       "      <td>305100.72270</td>\n",
       "      <td>286273.060500</td>\n",
       "      <td>1.412126e+06</td>\n",
       "      <td>13940.700700</td>\n",
       "      <td>26852.567400</td>\n",
       "      <td>47223.480600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101018WG.N.1.RL</th>\n",
       "      <td>73103.15772</td>\n",
       "      <td>1.937921e+05</td>\n",
       "      <td>254635.0241</td>\n",
       "      <td>61839.64963</td>\n",
       "      <td>23902.55961</td>\n",
       "      <td>9848.093782</td>\n",
       "      <td>26992.54855</td>\n",
       "      <td>12718.79319</td>\n",
       "      <td>7.705834e+06</td>\n",
       "      <td>7356.167218</td>\n",
       "      <td>...</td>\n",
       "      <td>2.947451e+05</td>\n",
       "      <td>151010.7498</td>\n",
       "      <td>2930.50564</td>\n",
       "      <td>10047.44791</td>\n",
       "      <td>13755.43464</td>\n",
       "      <td>9050.677283</td>\n",
       "      <td>4.363862e+04</td>\n",
       "      <td>2950.441053</td>\n",
       "      <td>3289.343065</td>\n",
       "      <td>9848.093782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 glutamic_acid       glycine      alanine  succinic_acid  \\\n",
       "#SampleID                                                                  \n",
       "100716FG.C.1.RL    60088.12140  8.110014e+05  144276.0444    30070.95780   \n",
       "100804MB.C.1.RL   120075.13440  1.931722e+06  197367.0879    84091.07970   \n",
       "100907LG.C.1.RL    19712.98000  1.569294e+05   51957.7830   213252.20150   \n",
       "101007PC.C.1.RL    17490.17800  1.268707e+06   90846.0422   297384.46770   \n",
       "101018WG.N.1.RL    73103.15772  1.937921e+05  254635.0241    61839.64963   \n",
       "\n",
       "                 aspartic_acid      glutamine       serine   methionine  \\\n",
       "#SampleID                                                                 \n",
       "100716FG.C.1.RL    67135.16160  386941.680600  48898.92780  27381.24780   \n",
       "100804MB.C.1.RL    98779.75800  950017.529700  44450.89110  18537.24030   \n",
       "100907LG.C.1.RL    38933.13550  693544.878500  28231.80350  22810.73400   \n",
       "101007PC.C.1.RL    42182.19400  241261.573000  26338.15040  47480.68910   \n",
       "101018WG.N.1.RL    23902.55961    9848.093782  26992.54855  12718.79319   \n",
       "\n",
       "                         urea       sucrose      ...        myristic_acid  \\\n",
       "#SampleID                                        ...                        \n",
       "100716FG.C.1.RL  6.677151e+06   6939.451800      ...         3.999599e+05   \n",
       "100804MB.C.1.RL  8.246570e+06  21936.803400      ...         7.797187e+05   \n",
       "100907LG.C.1.RL  1.427332e+07  17108.050500      ...         5.918822e+05   \n",
       "101007PC.C.1.RL  1.038325e+07  10288.340000      ...         1.184599e+06   \n",
       "101018WG.N.1.RL  7.705834e+06   7356.167218      ...         2.947451e+05   \n",
       "\n",
       "                 1_5_anhydroglucitol  azelaic_acid  behenic_acid  \\\n",
       "#SampleID                                                          \n",
       "100716FG.C.1.RL           86877.6330   47231.30760   26197.77540   \n",
       "100804MB.C.1.RL          330270.7623   43232.17980   73379.24880   \n",
       "100907LG.C.1.RL          648345.8315  126867.10700   57449.25600   \n",
       "101007PC.C.1.RL          910055.1147    8282.11370   22891.55650   \n",
       "101018WG.N.1.RL          151010.7498    2930.50564   10047.44791   \n",
       "\n",
       "                 palmitoleic_acid  dihydroabietic_acid  pentadecanoic_acid  \\\n",
       "#SampleID                                                                    \n",
       "100716FG.C.1.RL      131688.20160        203772.429600        4.797905e+05   \n",
       "100804MB.C.1.RL      273568.61550        677860.053600        9.592541e+05   \n",
       "100907LG.C.1.RL      281191.57900        548020.844000        8.000654e+05   \n",
       "101007PC.C.1.RL      305100.72270        286273.060500        1.412126e+06   \n",
       "101018WG.N.1.RL       13755.43464          9050.677283        4.363862e+04   \n",
       "\n",
       "                     threitol    octadecanol  1_monostearin  \n",
       "#SampleID                                                    \n",
       "100716FG.C.1.RL   5218.037400   36795.232800   42228.447000  \n",
       "100804MB.C.1.RL  18408.954900  127579.830300   91339.204800  \n",
       "100907LG.C.1.RL  23373.962000   47874.380000   76528.604500  \n",
       "101007PC.C.1.RL  13940.700700   26852.567400   47223.480600  \n",
       "101018WG.N.1.RL   2950.441053    3289.343065    9848.093782  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('~/Desktop/Clemente Lab/CUtIe/data/lung_pt/Mapping.Pneumotype.Multiomics.RL.NYU.w_metabolites.w_inflamm.txt', \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 0)\n",
    "df = df.set_index(list(df)[0])\n",
    "df = df.iloc[:,16:99]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(df)\n",
    "for col in cols:\n",
    "    col_zscore = col + '_zscore'\n",
    "    df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glutamic_acid</th>\n",
       "      <th>glycine</th>\n",
       "      <th>alanine</th>\n",
       "      <th>succinic_acid</th>\n",
       "      <th>aspartic_acid</th>\n",
       "      <th>glutamine</th>\n",
       "      <th>serine</th>\n",
       "      <th>methionine</th>\n",
       "      <th>urea</th>\n",
       "      <th>sucrose</th>\n",
       "      <th>...</th>\n",
       "      <th>myristic_acid_zscore</th>\n",
       "      <th>1_5_anhydroglucitol_zscore</th>\n",
       "      <th>azelaic_acid_zscore</th>\n",
       "      <th>behenic_acid_zscore</th>\n",
       "      <th>palmitoleic_acid_zscore</th>\n",
       "      <th>dihydroabietic_acid_zscore</th>\n",
       "      <th>pentadecanoic_acid_zscore</th>\n",
       "      <th>threitol_zscore</th>\n",
       "      <th>octadecanol_zscore</th>\n",
       "      <th>1_monostearin_zscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100716FG.C.1.RL</th>\n",
       "      <td>60088.12140</td>\n",
       "      <td>8.110014e+05</td>\n",
       "      <td>1.442760e+05</td>\n",
       "      <td>30070.95780</td>\n",
       "      <td>67135.161600</td>\n",
       "      <td>3.869417e+05</td>\n",
       "      <td>48898.927800</td>\n",
       "      <td>27381.247800</td>\n",
       "      <td>6.677151e+06</td>\n",
       "      <td>6939.451800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154014</td>\n",
       "      <td>-0.490959</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>-0.178554</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>-0.026283</td>\n",
       "      <td>-0.064912</td>\n",
       "      <td>-0.464823</td>\n",
       "      <td>-0.268445</td>\n",
       "      <td>-0.170103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100804MB.C.1.RL</th>\n",
       "      <td>120075.13440</td>\n",
       "      <td>1.931722e+06</td>\n",
       "      <td>1.973671e+05</td>\n",
       "      <td>84091.07970</td>\n",
       "      <td>98779.758000</td>\n",
       "      <td>9.500175e+05</td>\n",
       "      <td>44450.891100</td>\n",
       "      <td>18537.240300</td>\n",
       "      <td>8.246570e+06</td>\n",
       "      <td>21936.803400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448364</td>\n",
       "      <td>-0.347697</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>1.121355</td>\n",
       "      <td>0.545285</td>\n",
       "      <td>1.958865</td>\n",
       "      <td>0.587249</td>\n",
       "      <td>-0.159595</td>\n",
       "      <td>0.287325</td>\n",
       "      <td>0.139540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100907LG.C.1.RL</th>\n",
       "      <td>19712.98000</td>\n",
       "      <td>1.569294e+05</td>\n",
       "      <td>5.195778e+04</td>\n",
       "      <td>213252.20150</td>\n",
       "      <td>38933.135500</td>\n",
       "      <td>6.935449e+05</td>\n",
       "      <td>28231.803500</td>\n",
       "      <td>22810.734000</td>\n",
       "      <td>1.427332e+07</td>\n",
       "      <td>17108.050500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150416</td>\n",
       "      <td>-0.160478</td>\n",
       "      <td>1.193778</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.588133</td>\n",
       "      <td>1.415189</td>\n",
       "      <td>0.370722</td>\n",
       "      <td>-0.044708</td>\n",
       "      <td>-0.200620</td>\n",
       "      <td>0.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101007PC.C.1.RL</th>\n",
       "      <td>17490.17800</td>\n",
       "      <td>1.268707e+06</td>\n",
       "      <td>9.084604e+04</td>\n",
       "      <td>297384.46770</td>\n",
       "      <td>42182.194000</td>\n",
       "      <td>2.412616e+05</td>\n",
       "      <td>26338.150400</td>\n",
       "      <td>47480.689100</td>\n",
       "      <td>1.038325e+07</td>\n",
       "      <td>10288.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090590</td>\n",
       "      <td>-0.006435</td>\n",
       "      <td>-0.549014</td>\n",
       "      <td>-0.269645</td>\n",
       "      <td>0.722521</td>\n",
       "      <td>0.319172</td>\n",
       "      <td>1.203240</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>-0.329312</td>\n",
       "      <td>-0.138609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101018WG.N.1.RL</th>\n",
       "      <td>73103.15772</td>\n",
       "      <td>1.937921e+05</td>\n",
       "      <td>2.546350e+05</td>\n",
       "      <td>61839.64963</td>\n",
       "      <td>23902.559610</td>\n",
       "      <td>9.848094e+03</td>\n",
       "      <td>26992.548550</td>\n",
       "      <td>12718.793190</td>\n",
       "      <td>7.705834e+06</td>\n",
       "      <td>7356.167218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320907</td>\n",
       "      <td>-0.453210</td>\n",
       "      <td>-0.627664</td>\n",
       "      <td>-0.623516</td>\n",
       "      <td>-0.915074</td>\n",
       "      <td>-0.841642</td>\n",
       "      <td>-0.658160</td>\n",
       "      <td>-0.517293</td>\n",
       "      <td>-0.473563</td>\n",
       "      <td>-0.374261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101019AB.N.1.RL</th>\n",
       "      <td>91490.47715</td>\n",
       "      <td>4.593119e+04</td>\n",
       "      <td>1.996344e+05</td>\n",
       "      <td>24608.21100</td>\n",
       "      <td>12913.628780</td>\n",
       "      <td>1.070282e+04</td>\n",
       "      <td>8822.591180</td>\n",
       "      <td>12169.803760</td>\n",
       "      <td>1.086499e+07</td>\n",
       "      <td>3347.212579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.541941</td>\n",
       "      <td>-0.345710</td>\n",
       "      <td>-0.607268</td>\n",
       "      <td>-0.577566</td>\n",
       "      <td>-0.927354</td>\n",
       "      <td>-0.849692</td>\n",
       "      <td>-0.677862</td>\n",
       "      <td>-0.502375</td>\n",
       "      <td>-0.473461</td>\n",
       "      <td>-0.347637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101026RM.C.1.RL</th>\n",
       "      <td>74320.14650</td>\n",
       "      <td>1.801788e+06</td>\n",
       "      <td>2.080495e+05</td>\n",
       "      <td>130272.64150</td>\n",
       "      <td>17723.172500</td>\n",
       "      <td>1.711092e+05</td>\n",
       "      <td>70248.211000</td>\n",
       "      <td>30436.985500</td>\n",
       "      <td>1.143933e+07</td>\n",
       "      <td>21179.923500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386353</td>\n",
       "      <td>-0.145149</td>\n",
       "      <td>0.775844</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.425141</td>\n",
       "      <td>-0.223896</td>\n",
       "      <td>-0.302042</td>\n",
       "      <td>0.072631</td>\n",
       "      <td>-0.357762</td>\n",
       "      <td>-0.254606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101109JD.N.1.RL</th>\n",
       "      <td>223226.12320</td>\n",
       "      <td>1.154628e+05</td>\n",
       "      <td>5.118831e+05</td>\n",
       "      <td>33441.78939</td>\n",
       "      <td>66883.578790</td>\n",
       "      <td>2.004764e+04</td>\n",
       "      <td>33558.007590</td>\n",
       "      <td>20454.404630</td>\n",
       "      <td>6.536228e+06</td>\n",
       "      <td>3225.055275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085521</td>\n",
       "      <td>-0.408327</td>\n",
       "      <td>-0.607109</td>\n",
       "      <td>-0.432850</td>\n",
       "      <td>-0.876277</td>\n",
       "      <td>-0.827834</td>\n",
       "      <td>-0.594057</td>\n",
       "      <td>-0.498165</td>\n",
       "      <td>-0.463106</td>\n",
       "      <td>-0.324058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101206DM.N.1.RL</th>\n",
       "      <td>65152.37963</td>\n",
       "      <td>4.499920e+04</td>\n",
       "      <td>2.859891e+05</td>\n",
       "      <td>12792.41389</td>\n",
       "      <td>14365.812390</td>\n",
       "      <td>9.864525e+03</td>\n",
       "      <td>13025.003230</td>\n",
       "      <td>14803.627630</td>\n",
       "      <td>5.183513e+06</td>\n",
       "      <td>1778.624392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538448</td>\n",
       "      <td>-0.403655</td>\n",
       "      <td>-0.657260</td>\n",
       "      <td>-0.643634</td>\n",
       "      <td>-0.917564</td>\n",
       "      <td>-0.851296</td>\n",
       "      <td>-0.682382</td>\n",
       "      <td>-0.531112</td>\n",
       "      <td>-0.069719</td>\n",
       "      <td>-0.420998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110222MG.C.1.RL</th>\n",
       "      <td>18206.59680</td>\n",
       "      <td>9.360382e+04</td>\n",
       "      <td>2.130003e+05</td>\n",
       "      <td>33336.61590</td>\n",
       "      <td>38562.583500</td>\n",
       "      <td>1.571920e+06</td>\n",
       "      <td>38394.003900</td>\n",
       "      <td>22083.927600</td>\n",
       "      <td>2.888354e+07</td>\n",
       "      <td>46907.273700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166188</td>\n",
       "      <td>-0.241266</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>-0.444468</td>\n",
       "      <td>-0.131998</td>\n",
       "      <td>-0.122484</td>\n",
       "      <td>-0.033600</td>\n",
       "      <td>-0.231567</td>\n",
       "      <td>-0.234669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110228CJ.N.1.RL</th>\n",
       "      <td>55141.21631</td>\n",
       "      <td>4.191730e+04</td>\n",
       "      <td>2.302189e+05</td>\n",
       "      <td>21687.98274</td>\n",
       "      <td>14529.029150</td>\n",
       "      <td>7.120568e+03</td>\n",
       "      <td>16525.091280</td>\n",
       "      <td>11381.392710</td>\n",
       "      <td>8.769795e+06</td>\n",
       "      <td>1593.011122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283612</td>\n",
       "      <td>-0.476008</td>\n",
       "      <td>-0.636602</td>\n",
       "      <td>-0.587293</td>\n",
       "      <td>-0.924426</td>\n",
       "      <td>-0.835017</td>\n",
       "      <td>-0.691150</td>\n",
       "      <td>-0.507401</td>\n",
       "      <td>-0.480892</td>\n",
       "      <td>-0.387464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110308DK.C.1.RL</th>\n",
       "      <td>17355.92230</td>\n",
       "      <td>2.330841e+05</td>\n",
       "      <td>9.205898e+04</td>\n",
       "      <td>180158.43300</td>\n",
       "      <td>29828.429200</td>\n",
       "      <td>5.639025e+05</td>\n",
       "      <td>46128.477900</td>\n",
       "      <td>20325.566800</td>\n",
       "      <td>2.338932e+07</td>\n",
       "      <td>21051.479900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043123</td>\n",
       "      <td>-0.194100</td>\n",
       "      <td>0.747199</td>\n",
       "      <td>0.085110</td>\n",
       "      <td>0.352226</td>\n",
       "      <td>1.066644</td>\n",
       "      <td>0.233597</td>\n",
       "      <td>-0.183961</td>\n",
       "      <td>-0.196764</td>\n",
       "      <td>-0.096832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110314CS.N.1.RL</th>\n",
       "      <td>58504.80283</td>\n",
       "      <td>4.214692e+04</td>\n",
       "      <td>1.384215e+05</td>\n",
       "      <td>14801.06080</td>\n",
       "      <td>9611.664484</td>\n",
       "      <td>5.753461e+03</td>\n",
       "      <td>11439.234490</td>\n",
       "      <td>9340.913372</td>\n",
       "      <td>6.000544e+06</td>\n",
       "      <td>1872.695193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237176</td>\n",
       "      <td>-0.424551</td>\n",
       "      <td>-0.627293</td>\n",
       "      <td>-0.588901</td>\n",
       "      <td>-0.936589</td>\n",
       "      <td>-0.840994</td>\n",
       "      <td>-0.665805</td>\n",
       "      <td>-0.554762</td>\n",
       "      <td>0.151482</td>\n",
       "      <td>-0.360672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110330DS.C.1.RL</th>\n",
       "      <td>110596.56450</td>\n",
       "      <td>1.117430e+06</td>\n",
       "      <td>2.116038e+05</td>\n",
       "      <td>63161.50620</td>\n",
       "      <td>41766.718000</td>\n",
       "      <td>1.139209e+05</td>\n",
       "      <td>56640.783900</td>\n",
       "      <td>12316.919900</td>\n",
       "      <td>6.642357e+06</td>\n",
       "      <td>7969.771700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063664</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>-0.219131</td>\n",
       "      <td>-0.420084</td>\n",
       "      <td>1.047888</td>\n",
       "      <td>-0.188725</td>\n",
       "      <td>-0.133122</td>\n",
       "      <td>-0.238431</td>\n",
       "      <td>4.663925</td>\n",
       "      <td>-0.286411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110406MB.C.1.RL</th>\n",
       "      <td>272839.32020</td>\n",
       "      <td>2.580015e+06</td>\n",
       "      <td>2.801887e+05</td>\n",
       "      <td>73928.41000</td>\n",
       "      <td>159250.492600</td>\n",
       "      <td>3.520732e+05</td>\n",
       "      <td>76885.546400</td>\n",
       "      <td>15959.839100</td>\n",
       "      <td>9.073277e+06</td>\n",
       "      <td>6697.044200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238885</td>\n",
       "      <td>-0.297417</td>\n",
       "      <td>-0.513510</td>\n",
       "      <td>-0.205421</td>\n",
       "      <td>1.348550</td>\n",
       "      <td>0.131631</td>\n",
       "      <td>0.282961</td>\n",
       "      <td>-0.428587</td>\n",
       "      <td>0.034753</td>\n",
       "      <td>-0.189584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110412ET.C.1.RL</th>\n",
       "      <td>322618.11880</td>\n",
       "      <td>1.786408e+06</td>\n",
       "      <td>5.978764e+05</td>\n",
       "      <td>88925.71260</td>\n",
       "      <td>78597.230400</td>\n",
       "      <td>3.007856e+05</td>\n",
       "      <td>82124.029200</td>\n",
       "      <td>12259.824400</td>\n",
       "      <td>6.635336e+06</td>\n",
       "      <td>17046.194200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315521</td>\n",
       "      <td>-0.345702</td>\n",
       "      <td>-0.275206</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>1.031253</td>\n",
       "      <td>0.253359</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>-0.210558</td>\n",
       "      <td>-0.284991</td>\n",
       "      <td>-0.247608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110418ML.C.1.RL</th>\n",
       "      <td>114864.32300</td>\n",
       "      <td>1.019225e+06</td>\n",
       "      <td>1.884447e+04</td>\n",
       "      <td>133013.00200</td>\n",
       "      <td>80596.370000</td>\n",
       "      <td>8.841828e+05</td>\n",
       "      <td>36065.426000</td>\n",
       "      <td>17800.781000</td>\n",
       "      <td>9.260987e+06</td>\n",
       "      <td>4812.589000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358184</td>\n",
       "      <td>-0.289269</td>\n",
       "      <td>0.452403</td>\n",
       "      <td>-0.192641</td>\n",
       "      <td>-0.340568</td>\n",
       "      <td>-0.249494</td>\n",
       "      <td>-0.248333</td>\n",
       "      <td>-0.256852</td>\n",
       "      <td>-0.292080</td>\n",
       "      <td>-0.336549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110420JR.C.1.RL</th>\n",
       "      <td>215248.43880</td>\n",
       "      <td>4.010056e+06</td>\n",
       "      <td>2.428420e+05</td>\n",
       "      <td>60779.26530</td>\n",
       "      <td>159633.424800</td>\n",
       "      <td>9.439274e+04</td>\n",
       "      <td>81864.078300</td>\n",
       "      <td>13353.714900</td>\n",
       "      <td>1.693025e+07</td>\n",
       "      <td>5867.078400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556501</td>\n",
       "      <td>-0.203809</td>\n",
       "      <td>-0.591692</td>\n",
       "      <td>-0.317739</td>\n",
       "      <td>-0.296080</td>\n",
       "      <td>-0.275468</td>\n",
       "      <td>-0.386125</td>\n",
       "      <td>-0.357884</td>\n",
       "      <td>-0.411202</td>\n",
       "      <td>-0.282220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110502BC.N.1.RL</th>\n",
       "      <td>57435.66899</td>\n",
       "      <td>3.188242e+04</td>\n",
       "      <td>1.967561e+05</td>\n",
       "      <td>23009.75822</td>\n",
       "      <td>5323.594447</td>\n",
       "      <td>5.303877e+03</td>\n",
       "      <td>5934.821959</td>\n",
       "      <td>9543.035971</td>\n",
       "      <td>4.744900e+06</td>\n",
       "      <td>4377.177657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647101</td>\n",
       "      <td>-0.400903</td>\n",
       "      <td>-0.633062</td>\n",
       "      <td>-0.537459</td>\n",
       "      <td>-0.936756</td>\n",
       "      <td>-0.830912</td>\n",
       "      <td>-0.634352</td>\n",
       "      <td>-0.487017</td>\n",
       "      <td>-0.457005</td>\n",
       "      <td>-0.361018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110523CB.C.1.RL</th>\n",
       "      <td>97961.56240</td>\n",
       "      <td>1.257122e+06</td>\n",
       "      <td>1.947285e+05</td>\n",
       "      <td>40309.91120</td>\n",
       "      <td>63740.528800</td>\n",
       "      <td>4.715412e+05</td>\n",
       "      <td>65089.330800</td>\n",
       "      <td>14258.764000</td>\n",
       "      <td>1.966904e+07</td>\n",
       "      <td>16648.070400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267990</td>\n",
       "      <td>-0.360313</td>\n",
       "      <td>-0.443620</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>-0.036033</td>\n",
       "      <td>-0.241359</td>\n",
       "      <td>-0.236784</td>\n",
       "      <td>-0.122427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110601OG.C.1.RL</th>\n",
       "      <td>32662.60130</td>\n",
       "      <td>2.356013e+05</td>\n",
       "      <td>2.990483e+05</td>\n",
       "      <td>69722.97220</td>\n",
       "      <td>55430.221000</td>\n",
       "      <td>3.030705e+06</td>\n",
       "      <td>74487.222600</td>\n",
       "      <td>49887.198900</td>\n",
       "      <td>2.457327e+07</td>\n",
       "      <td>39259.255700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633537</td>\n",
       "      <td>0.382120</td>\n",
       "      <td>0.170832</td>\n",
       "      <td>0.322664</td>\n",
       "      <td>0.548428</td>\n",
       "      <td>0.126943</td>\n",
       "      <td>0.296708</td>\n",
       "      <td>0.424628</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>-0.066070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110720BB.C.1.RL</th>\n",
       "      <td>53034.47140</td>\n",
       "      <td>1.266820e+06</td>\n",
       "      <td>1.648724e+05</td>\n",
       "      <td>52915.11400</td>\n",
       "      <td>36284.649600</td>\n",
       "      <td>5.068711e+04</td>\n",
       "      <td>36602.936000</td>\n",
       "      <td>7161.444000</td>\n",
       "      <td>1.777116e+07</td>\n",
       "      <td>9548.592000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316571</td>\n",
       "      <td>-0.386647</td>\n",
       "      <td>-0.426906</td>\n",
       "      <td>-0.218531</td>\n",
       "      <td>-0.221991</td>\n",
       "      <td>-0.458387</td>\n",
       "      <td>-0.292489</td>\n",
       "      <td>-0.325031</td>\n",
       "      <td>-0.206539</td>\n",
       "      <td>-0.068608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110727MK.C.1.RL</th>\n",
       "      <td>186826.46350</td>\n",
       "      <td>2.687663e+06</td>\n",
       "      <td>2.291757e+05</td>\n",
       "      <td>121713.07450</td>\n",
       "      <td>67817.312000</td>\n",
       "      <td>6.109404e+04</td>\n",
       "      <td>56015.053500</td>\n",
       "      <td>21850.621000</td>\n",
       "      <td>7.261970e+06</td>\n",
       "      <td>8294.466500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.563842</td>\n",
       "      <td>0.374199</td>\n",
       "      <td>0.465571</td>\n",
       "      <td>-0.387921</td>\n",
       "      <td>-0.449773</td>\n",
       "      <td>-0.520903</td>\n",
       "      <td>-0.399632</td>\n",
       "      <td>0.815425</td>\n",
       "      <td>-0.363736</td>\n",
       "      <td>-0.161278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110801EH.C.1.RL</th>\n",
       "      <td>309002.92800</td>\n",
       "      <td>9.278219e+06</td>\n",
       "      <td>1.930184e+06</td>\n",
       "      <td>377850.94880</td>\n",
       "      <td>316050.363200</td>\n",
       "      <td>1.908229e+05</td>\n",
       "      <td>604724.151200</td>\n",
       "      <td>115198.460000</td>\n",
       "      <td>9.170340e+07</td>\n",
       "      <td>119535.343200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.771689</td>\n",
       "      <td>4.419716</td>\n",
       "      <td>1.161715</td>\n",
       "      <td>4.170378</td>\n",
       "      <td>3.549307</td>\n",
       "      <td>3.516277</td>\n",
       "      <td>4.586767</td>\n",
       "      <td>4.745655</td>\n",
       "      <td>1.877525</td>\n",
       "      <td>5.006819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110808JB.N.1.RL</th>\n",
       "      <td>160898.04280</td>\n",
       "      <td>1.534516e+05</td>\n",
       "      <td>4.442620e+05</td>\n",
       "      <td>29354.89250</td>\n",
       "      <td>53232.666690</td>\n",
       "      <td>6.861783e+03</td>\n",
       "      <td>28770.256270</td>\n",
       "      <td>12400.442010</td>\n",
       "      <td>7.699782e+06</td>\n",
       "      <td>1630.827361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443409</td>\n",
       "      <td>-0.409483</td>\n",
       "      <td>-0.619179</td>\n",
       "      <td>-0.345900</td>\n",
       "      <td>-0.915772</td>\n",
       "      <td>-0.849648</td>\n",
       "      <td>-0.661433</td>\n",
       "      <td>-0.483036</td>\n",
       "      <td>-0.465255</td>\n",
       "      <td>-0.352542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110921AR.C.1.RL</th>\n",
       "      <td>289463.80200</td>\n",
       "      <td>5.687573e+06</td>\n",
       "      <td>5.260569e+05</td>\n",
       "      <td>487823.47800</td>\n",
       "      <td>136151.457000</td>\n",
       "      <td>9.097794e+04</td>\n",
       "      <td>140946.411000</td>\n",
       "      <td>40126.194000</td>\n",
       "      <td>5.594525e+07</td>\n",
       "      <td>53249.226000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>2.317585</td>\n",
       "      <td>4.295502</td>\n",
       "      <td>2.113791</td>\n",
       "      <td>1.196355</td>\n",
       "      <td>0.749942</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>1.177985</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>1.017974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111003JG.C.1.RL</th>\n",
       "      <td>193512.07190</td>\n",
       "      <td>2.382799e+06</td>\n",
       "      <td>7.449343e+05</td>\n",
       "      <td>19887.69660</td>\n",
       "      <td>110065.757300</td>\n",
       "      <td>4.478832e+05</td>\n",
       "      <td>94210.274100</td>\n",
       "      <td>69231.053800</td>\n",
       "      <td>8.987667e+06</td>\n",
       "      <td>6492.547000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.589293</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>-0.559746</td>\n",
       "      <td>-0.842907</td>\n",
       "      <td>-0.490895</td>\n",
       "      <td>-0.787679</td>\n",
       "      <td>-0.482192</td>\n",
       "      <td>0.311879</td>\n",
       "      <td>-0.426549</td>\n",
       "      <td>-0.319795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111115WK.C.1.RL</th>\n",
       "      <td>142062.84000</td>\n",
       "      <td>2.065673e+06</td>\n",
       "      <td>6.194729e+05</td>\n",
       "      <td>56746.21220</td>\n",
       "      <td>96405.421700</td>\n",
       "      <td>4.755554e+05</td>\n",
       "      <td>93287.931600</td>\n",
       "      <td>15626.912400</td>\n",
       "      <td>1.863422e+07</td>\n",
       "      <td>6116.594500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575362</td>\n",
       "      <td>-0.515849</td>\n",
       "      <td>-0.512985</td>\n",
       "      <td>-0.545901</td>\n",
       "      <td>-0.710695</td>\n",
       "      <td>-0.642587</td>\n",
       "      <td>-0.423267</td>\n",
       "      <td>-0.258668</td>\n",
       "      <td>-0.319279</td>\n",
       "      <td>-0.306476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows  166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 glutamic_acid       glycine       alanine  succinic_acid  \\\n",
       "#SampleID                                                                   \n",
       "100716FG.C.1.RL    60088.12140  8.110014e+05  1.442760e+05    30070.95780   \n",
       "100804MB.C.1.RL   120075.13440  1.931722e+06  1.973671e+05    84091.07970   \n",
       "100907LG.C.1.RL    19712.98000  1.569294e+05  5.195778e+04   213252.20150   \n",
       "101007PC.C.1.RL    17490.17800  1.268707e+06  9.084604e+04   297384.46770   \n",
       "101018WG.N.1.RL    73103.15772  1.937921e+05  2.546350e+05    61839.64963   \n",
       "101019AB.N.1.RL    91490.47715  4.593119e+04  1.996344e+05    24608.21100   \n",
       "101026RM.C.1.RL    74320.14650  1.801788e+06  2.080495e+05   130272.64150   \n",
       "101109JD.N.1.RL   223226.12320  1.154628e+05  5.118831e+05    33441.78939   \n",
       "101206DM.N.1.RL    65152.37963  4.499920e+04  2.859891e+05    12792.41389   \n",
       "110222MG.C.1.RL    18206.59680  9.360382e+04  2.130003e+05    33336.61590   \n",
       "110228CJ.N.1.RL    55141.21631  4.191730e+04  2.302189e+05    21687.98274   \n",
       "110308DK.C.1.RL    17355.92230  2.330841e+05  9.205898e+04   180158.43300   \n",
       "110314CS.N.1.RL    58504.80283  4.214692e+04  1.384215e+05    14801.06080   \n",
       "110330DS.C.1.RL   110596.56450  1.117430e+06  2.116038e+05    63161.50620   \n",
       "110406MB.C.1.RL   272839.32020  2.580015e+06  2.801887e+05    73928.41000   \n",
       "110412ET.C.1.RL   322618.11880  1.786408e+06  5.978764e+05    88925.71260   \n",
       "110418ML.C.1.RL   114864.32300  1.019225e+06  1.884447e+04   133013.00200   \n",
       "110420JR.C.1.RL   215248.43880  4.010056e+06  2.428420e+05    60779.26530   \n",
       "110502BC.N.1.RL    57435.66899  3.188242e+04  1.967561e+05    23009.75822   \n",
       "110523CB.C.1.RL    97961.56240  1.257122e+06  1.947285e+05    40309.91120   \n",
       "110601OG.C.1.RL    32662.60130  2.356013e+05  2.990483e+05    69722.97220   \n",
       "110720BB.C.1.RL    53034.47140  1.266820e+06  1.648724e+05    52915.11400   \n",
       "110727MK.C.1.RL   186826.46350  2.687663e+06  2.291757e+05   121713.07450   \n",
       "110801EH.C.1.RL   309002.92800  9.278219e+06  1.930184e+06   377850.94880   \n",
       "110808JB.N.1.RL   160898.04280  1.534516e+05  4.442620e+05    29354.89250   \n",
       "110921AR.C.1.RL   289463.80200  5.687573e+06  5.260569e+05   487823.47800   \n",
       "111003JG.C.1.RL   193512.07190  2.382799e+06  7.449343e+05    19887.69660   \n",
       "111115WK.C.1.RL   142062.84000  2.065673e+06  6.194729e+05    56746.21220   \n",
       "\n",
       "                 aspartic_acid     glutamine         serine     methionine  \\\n",
       "#SampleID                                                                    \n",
       "100716FG.C.1.RL   67135.161600  3.869417e+05   48898.927800   27381.247800   \n",
       "100804MB.C.1.RL   98779.758000  9.500175e+05   44450.891100   18537.240300   \n",
       "100907LG.C.1.RL   38933.135500  6.935449e+05   28231.803500   22810.734000   \n",
       "101007PC.C.1.RL   42182.194000  2.412616e+05   26338.150400   47480.689100   \n",
       "101018WG.N.1.RL   23902.559610  9.848094e+03   26992.548550   12718.793190   \n",
       "101019AB.N.1.RL   12913.628780  1.070282e+04    8822.591180   12169.803760   \n",
       "101026RM.C.1.RL   17723.172500  1.711092e+05   70248.211000   30436.985500   \n",
       "101109JD.N.1.RL   66883.578790  2.004764e+04   33558.007590   20454.404630   \n",
       "101206DM.N.1.RL   14365.812390  9.864525e+03   13025.003230   14803.627630   \n",
       "110222MG.C.1.RL   38562.583500  1.571920e+06   38394.003900   22083.927600   \n",
       "110228CJ.N.1.RL   14529.029150  7.120568e+03   16525.091280   11381.392710   \n",
       "110308DK.C.1.RL   29828.429200  5.639025e+05   46128.477900   20325.566800   \n",
       "110314CS.N.1.RL    9611.664484  5.753461e+03   11439.234490    9340.913372   \n",
       "110330DS.C.1.RL   41766.718000  1.139209e+05   56640.783900   12316.919900   \n",
       "110406MB.C.1.RL  159250.492600  3.520732e+05   76885.546400   15959.839100   \n",
       "110412ET.C.1.RL   78597.230400  3.007856e+05   82124.029200   12259.824400   \n",
       "110418ML.C.1.RL   80596.370000  8.841828e+05   36065.426000   17800.781000   \n",
       "110420JR.C.1.RL  159633.424800  9.439274e+04   81864.078300   13353.714900   \n",
       "110502BC.N.1.RL    5323.594447  5.303877e+03    5934.821959    9543.035971   \n",
       "110523CB.C.1.RL   63740.528800  4.715412e+05   65089.330800   14258.764000   \n",
       "110601OG.C.1.RL   55430.221000  3.030705e+06   74487.222600   49887.198900   \n",
       "110720BB.C.1.RL   36284.649600  5.068711e+04   36602.936000    7161.444000   \n",
       "110727MK.C.1.RL   67817.312000  6.109404e+04   56015.053500   21850.621000   \n",
       "110801EH.C.1.RL  316050.363200  1.908229e+05  604724.151200  115198.460000   \n",
       "110808JB.N.1.RL   53232.666690  6.861783e+03   28770.256270   12400.442010   \n",
       "110921AR.C.1.RL  136151.457000  9.097794e+04  140946.411000   40126.194000   \n",
       "111003JG.C.1.RL  110065.757300  4.478832e+05   94210.274100   69231.053800   \n",
       "111115WK.C.1.RL   96405.421700  4.755554e+05   93287.931600   15626.912400   \n",
       "\n",
       "                         urea        sucrose          ...           \\\n",
       "#SampleID                                             ...            \n",
       "100716FG.C.1.RL  6.677151e+06    6939.451800          ...            \n",
       "100804MB.C.1.RL  8.246570e+06   21936.803400          ...            \n",
       "100907LG.C.1.RL  1.427332e+07   17108.050500          ...            \n",
       "101007PC.C.1.RL  1.038325e+07   10288.340000          ...            \n",
       "101018WG.N.1.RL  7.705834e+06    7356.167218          ...            \n",
       "101019AB.N.1.RL  1.086499e+07    3347.212579          ...            \n",
       "101026RM.C.1.RL  1.143933e+07   21179.923500          ...            \n",
       "101109JD.N.1.RL  6.536228e+06    3225.055275          ...            \n",
       "101206DM.N.1.RL  5.183513e+06    1778.624392          ...            \n",
       "110222MG.C.1.RL  2.888354e+07   46907.273700          ...            \n",
       "110228CJ.N.1.RL  8.769795e+06    1593.011122          ...            \n",
       "110308DK.C.1.RL  2.338932e+07   21051.479900          ...            \n",
       "110314CS.N.1.RL  6.000544e+06    1872.695193          ...            \n",
       "110330DS.C.1.RL  6.642357e+06    7969.771700          ...            \n",
       "110406MB.C.1.RL  9.073277e+06    6697.044200          ...            \n",
       "110412ET.C.1.RL  6.635336e+06   17046.194200          ...            \n",
       "110418ML.C.1.RL  9.260987e+06    4812.589000          ...            \n",
       "110420JR.C.1.RL  1.693025e+07    5867.078400          ...            \n",
       "110502BC.N.1.RL  4.744900e+06    4377.177657          ...            \n",
       "110523CB.C.1.RL  1.966904e+07   16648.070400          ...            \n",
       "110601OG.C.1.RL  2.457327e+07   39259.255700          ...            \n",
       "110720BB.C.1.RL  1.777116e+07    9548.592000          ...            \n",
       "110727MK.C.1.RL  7.261970e+06    8294.466500          ...            \n",
       "110801EH.C.1.RL  9.170340e+07  119535.343200          ...            \n",
       "110808JB.N.1.RL  7.699782e+06    1630.827361          ...            \n",
       "110921AR.C.1.RL  5.594525e+07   53249.226000          ...            \n",
       "111003JG.C.1.RL  8.987667e+06    6492.547000          ...            \n",
       "111115WK.C.1.RL  1.863422e+07    6116.594500          ...            \n",
       "\n",
       "                 myristic_acid_zscore  1_5_anhydroglucitol_zscore  \\\n",
       "#SampleID                                                           \n",
       "100716FG.C.1.RL             -0.154014                   -0.490959   \n",
       "100804MB.C.1.RL              0.448364                   -0.347697   \n",
       "100907LG.C.1.RL              0.150416                   -0.160478   \n",
       "101007PC.C.1.RL              1.090590                   -0.006435   \n",
       "101018WG.N.1.RL             -0.320907                   -0.453210   \n",
       "101019AB.N.1.RL             -0.541941                   -0.345710   \n",
       "101026RM.C.1.RL             -0.386353                   -0.145149   \n",
       "101109JD.N.1.RL             -0.085521                   -0.408327   \n",
       "101206DM.N.1.RL             -0.538448                   -0.403655   \n",
       "110222MG.C.1.RL             -0.166188                   -0.241266   \n",
       "110228CJ.N.1.RL             -0.283612                   -0.476008   \n",
       "110308DK.C.1.RL              0.043123                   -0.194100   \n",
       "110314CS.N.1.RL             -0.237176                   -0.424551   \n",
       "110330DS.C.1.RL             -0.063664                   -0.189115   \n",
       "110406MB.C.1.RL              0.238885                   -0.297417   \n",
       "110412ET.C.1.RL             -0.315521                   -0.345702   \n",
       "110418ML.C.1.RL             -0.358184                   -0.289269   \n",
       "110420JR.C.1.RL             -0.556501                   -0.203809   \n",
       "110502BC.N.1.RL             -0.647101                   -0.400903   \n",
       "110523CB.C.1.RL             -0.267990                   -0.360313   \n",
       "110601OG.C.1.RL              0.633537                    0.382120   \n",
       "110720BB.C.1.RL             -0.316571                   -0.386647   \n",
       "110727MK.C.1.RL             -0.563842                    0.374199   \n",
       "110801EH.C.1.RL              4.771689                    4.419716   \n",
       "110808JB.N.1.RL             -0.443409                   -0.409483   \n",
       "110921AR.C.1.RL              0.034994                    2.317585   \n",
       "111003JG.C.1.RL             -0.589293                    0.002432   \n",
       "111115WK.C.1.RL             -0.575362                   -0.515849   \n",
       "\n",
       "                 azelaic_acid_zscore  behenic_acid_zscore  \\\n",
       "#SampleID                                                   \n",
       "100716FG.C.1.RL             0.023406            -0.178554   \n",
       "100804MB.C.1.RL            -0.035368             1.121355   \n",
       "100907LG.C.1.RL             1.193778             0.682464   \n",
       "101007PC.C.1.RL            -0.549014            -0.269645   \n",
       "101018WG.N.1.RL            -0.627664            -0.623516   \n",
       "101019AB.N.1.RL            -0.607268            -0.577566   \n",
       "101026RM.C.1.RL             0.775844            -0.415269   \n",
       "101109JD.N.1.RL            -0.607109            -0.432850   \n",
       "101206DM.N.1.RL            -0.657260            -0.643634   \n",
       "110222MG.C.1.RL            -0.143635             0.007680   \n",
       "110228CJ.N.1.RL            -0.636602            -0.587293   \n",
       "110308DK.C.1.RL             0.747199             0.085110   \n",
       "110314CS.N.1.RL            -0.627293            -0.588901   \n",
       "110330DS.C.1.RL            -0.219131            -0.420084   \n",
       "110406MB.C.1.RL            -0.513510            -0.205421   \n",
       "110412ET.C.1.RL            -0.275206            -0.199340   \n",
       "110418ML.C.1.RL             0.452403            -0.192641   \n",
       "110420JR.C.1.RL            -0.591692            -0.317739   \n",
       "110502BC.N.1.RL            -0.633062            -0.537459   \n",
       "110523CB.C.1.RL            -0.443620             0.027632   \n",
       "110601OG.C.1.RL             0.170832             0.322664   \n",
       "110720BB.C.1.RL            -0.426906            -0.218531   \n",
       "110727MK.C.1.RL             0.465571            -0.387921   \n",
       "110801EH.C.1.RL             1.161715             4.170378   \n",
       "110808JB.N.1.RL            -0.619179            -0.345900   \n",
       "110921AR.C.1.RL             4.295502             2.113791   \n",
       "111003JG.C.1.RL            -0.559746            -0.842907   \n",
       "111115WK.C.1.RL            -0.512985            -0.545901   \n",
       "\n",
       "                 palmitoleic_acid_zscore  dihydroabietic_acid_zscore  \\\n",
       "#SampleID                                                              \n",
       "100716FG.C.1.RL                -0.252197                   -0.026283   \n",
       "100804MB.C.1.RL                 0.545285                    1.958865   \n",
       "100907LG.C.1.RL                 0.588133                    1.415189   \n",
       "101007PC.C.1.RL                 0.722521                    0.319172   \n",
       "101018WG.N.1.RL                -0.915074                   -0.841642   \n",
       "101019AB.N.1.RL                -0.927354                   -0.849692   \n",
       "101026RM.C.1.RL                -0.425141                   -0.223896   \n",
       "101109JD.N.1.RL                -0.876277                   -0.827834   \n",
       "101206DM.N.1.RL                -0.917564                   -0.851296   \n",
       "110222MG.C.1.RL                -0.444468                   -0.131998   \n",
       "110228CJ.N.1.RL                -0.924426                   -0.835017   \n",
       "110308DK.C.1.RL                 0.352226                    1.066644   \n",
       "110314CS.N.1.RL                -0.936589                   -0.840994   \n",
       "110330DS.C.1.RL                 1.047888                   -0.188725   \n",
       "110406MB.C.1.RL                 1.348550                    0.131631   \n",
       "110412ET.C.1.RL                 1.031253                    0.253359   \n",
       "110418ML.C.1.RL                -0.340568                   -0.249494   \n",
       "110420JR.C.1.RL                -0.296080                   -0.275468   \n",
       "110502BC.N.1.RL                -0.936756                   -0.830912   \n",
       "110523CB.C.1.RL                 0.051670                    0.694433   \n",
       "110601OG.C.1.RL                 0.548428                    0.126943   \n",
       "110720BB.C.1.RL                -0.221991                   -0.458387   \n",
       "110727MK.C.1.RL                -0.449773                   -0.520903   \n",
       "110801EH.C.1.RL                 3.549307                    3.516277   \n",
       "110808JB.N.1.RL                -0.915772                   -0.849648   \n",
       "110921AR.C.1.RL                 1.196355                    0.749942   \n",
       "111003JG.C.1.RL                -0.490895                   -0.787679   \n",
       "111115WK.C.1.RL                -0.710695                   -0.642587   \n",
       "\n",
       "                 pentadecanoic_acid_zscore  threitol_zscore  \\\n",
       "#SampleID                                                     \n",
       "100716FG.C.1.RL                  -0.064912        -0.464823   \n",
       "100804MB.C.1.RL                   0.587249        -0.159595   \n",
       "100907LG.C.1.RL                   0.370722        -0.044708   \n",
       "101007PC.C.1.RL                   1.203240        -0.262987   \n",
       "101018WG.N.1.RL                  -0.658160        -0.517293   \n",
       "101019AB.N.1.RL                  -0.677862        -0.502375   \n",
       "101026RM.C.1.RL                  -0.302042         0.072631   \n",
       "101109JD.N.1.RL                  -0.594057        -0.498165   \n",
       "101206DM.N.1.RL                  -0.682382        -0.531112   \n",
       "110222MG.C.1.RL                  -0.122484        -0.033600   \n",
       "110228CJ.N.1.RL                  -0.691150        -0.507401   \n",
       "110308DK.C.1.RL                   0.233597        -0.183961   \n",
       "110314CS.N.1.RL                  -0.665805        -0.554762   \n",
       "110330DS.C.1.RL                  -0.133122        -0.238431   \n",
       "110406MB.C.1.RL                   0.282961        -0.428587   \n",
       "110412ET.C.1.RL                   0.011986        -0.210558   \n",
       "110418ML.C.1.RL                  -0.248333        -0.256852   \n",
       "110420JR.C.1.RL                  -0.386125        -0.357884   \n",
       "110502BC.N.1.RL                  -0.634352        -0.487017   \n",
       "110523CB.C.1.RL                  -0.036033        -0.241359   \n",
       "110601OG.C.1.RL                   0.296708         0.424628   \n",
       "110720BB.C.1.RL                  -0.292489        -0.325031   \n",
       "110727MK.C.1.RL                  -0.399632         0.815425   \n",
       "110801EH.C.1.RL                   4.586767         4.745655   \n",
       "110808JB.N.1.RL                  -0.661433        -0.483036   \n",
       "110921AR.C.1.RL                   0.582600         1.177985   \n",
       "111003JG.C.1.RL                  -0.482192         0.311879   \n",
       "111115WK.C.1.RL                  -0.423267        -0.258668   \n",
       "\n",
       "                 octadecanol_zscore  1_monostearin_zscore  \n",
       "#SampleID                                                  \n",
       "100716FG.C.1.RL           -0.268445             -0.170103  \n",
       "100804MB.C.1.RL            0.287325              0.139540  \n",
       "100907LG.C.1.RL           -0.200620              0.046160  \n",
       "101007PC.C.1.RL           -0.329312             -0.138609  \n",
       "101018WG.N.1.RL           -0.473563             -0.374261  \n",
       "101019AB.N.1.RL           -0.473461             -0.347637  \n",
       "101026RM.C.1.RL           -0.357762             -0.254606  \n",
       "101109JD.N.1.RL           -0.463106             -0.324058  \n",
       "101206DM.N.1.RL           -0.069719             -0.420998  \n",
       "110222MG.C.1.RL           -0.231567             -0.234669  \n",
       "110228CJ.N.1.RL           -0.480892             -0.387464  \n",
       "110308DK.C.1.RL           -0.196764             -0.096832  \n",
       "110314CS.N.1.RL            0.151482             -0.360672  \n",
       "110330DS.C.1.RL            4.663925             -0.286411  \n",
       "110406MB.C.1.RL            0.034753             -0.189584  \n",
       "110412ET.C.1.RL           -0.284991             -0.247608  \n",
       "110418ML.C.1.RL           -0.292080             -0.336549  \n",
       "110420JR.C.1.RL           -0.411202             -0.282220  \n",
       "110502BC.N.1.RL           -0.457005             -0.361018  \n",
       "110523CB.C.1.RL           -0.236784             -0.122427  \n",
       "110601OG.C.1.RL           -0.006290             -0.066070  \n",
       "110720BB.C.1.RL           -0.206539             -0.068608  \n",
       "110727MK.C.1.RL           -0.363736             -0.161278  \n",
       "110801EH.C.1.RL            1.877525              5.006819  \n",
       "110808JB.N.1.RL           -0.465255             -0.352542  \n",
       "110921AR.C.1.RL           -0.000089              1.017974  \n",
       "111003JG.C.1.RL           -0.426549             -0.319795  \n",
       "111115WK.C.1.RL           -0.319279             -0.306476  \n",
       "\n",
       "[28 rows x 166 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryID</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Adolescent fertility rate (%)</th>\n",
       "      <th>Adult literacy rate (%)</th>\n",
       "      <th>Gross national income per capita (PPP international $)</th>\n",
       "      <th>Net primary school enrolment ratio female (%)</th>\n",
       "      <th>Net primary school enrolment ratio male (%)</th>\n",
       "      <th>Population (in thousands) total</th>\n",
       "      <th>Population annual growth rate (%)</th>\n",
       "      <th>Population in urban areas (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_CO2_emissions</th>\n",
       "      <th>Total_income</th>\n",
       "      <th>Total_reserves</th>\n",
       "      <th>Trade_balance_goods_and_services</th>\n",
       "      <th>Under_five_mortality_from_CME</th>\n",
       "      <th>Under_five_mortality_from_IHME</th>\n",
       "      <th>Under_five_mortality_rate</th>\n",
       "      <th>Urban_population</th>\n",
       "      <th>Urban_population_growth</th>\n",
       "      <th>Urban_population_pct_of_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26088.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.00</td>\n",
       "      <td>231.9</td>\n",
       "      <td>257.00</td>\n",
       "      <td>5740436.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3499.12</td>\n",
       "      <td>4.790000e+09</td>\n",
       "      <td>78.14</td>\n",
       "      <td>-2.040000e+09</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.47</td>\n",
       "      <td>1431793.9</td>\n",
       "      <td>2.21</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33351.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137535.56</td>\n",
       "      <td>6.970000e+10</td>\n",
       "      <td>351.36</td>\n",
       "      <td>4.700000e+09</td>\n",
       "      <td>40.00</td>\n",
       "      <td>31.2</td>\n",
       "      <td>40.00</td>\n",
       "      <td>20800000.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>16557.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8991.46</td>\n",
       "      <td>1.490000e+10</td>\n",
       "      <td>27.13</td>\n",
       "      <td>9.140000e+09</td>\n",
       "      <td>164.10</td>\n",
       "      <td>242.5</td>\n",
       "      <td>164.10</td>\n",
       "      <td>8578749.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CountryID  Continent  Adolescent fertility rate (%)  \\\n",
       "Country                                                            \n",
       "Afghanistan          1          1                          151.0   \n",
       "Albania              2          2                           27.0   \n",
       "Algeria              3          3                            6.0   \n",
       "Andorra              4          2                            NaN   \n",
       "Angola               5          3                          146.0   \n",
       "\n",
       "             Adult literacy rate (%)  \\\n",
       "Country                                \n",
       "Afghanistan                     28.0   \n",
       "Albania                         98.7   \n",
       "Algeria                         69.9   \n",
       "Andorra                          NaN   \n",
       "Angola                          67.4   \n",
       "\n",
       "             Gross national income per capita (PPP international $)  \\\n",
       "Country                                                               \n",
       "Afghanistan                                                NaN        \n",
       "Albania                                                 6000.0        \n",
       "Algeria                                                 5940.0        \n",
       "Andorra                                                    NaN        \n",
       "Angola                                                  3890.0        \n",
       "\n",
       "             Net primary school enrolment ratio female (%)  \\\n",
       "Country                                                      \n",
       "Afghanistan                                            NaN   \n",
       "Albania                                               93.0   \n",
       "Algeria                                               94.0   \n",
       "Andorra                                               83.0   \n",
       "Angola                                                49.0   \n",
       "\n",
       "             Net primary school enrolment ratio male (%)  \\\n",
       "Country                                                    \n",
       "Afghanistan                                          NaN   \n",
       "Albania                                             94.0   \n",
       "Algeria                                             96.0   \n",
       "Andorra                                             83.0   \n",
       "Angola                                              51.0   \n",
       "\n",
       "             Population (in thousands) total  \\\n",
       "Country                                        \n",
       "Afghanistan                          26088.0   \n",
       "Albania                               3172.0   \n",
       "Algeria                              33351.0   \n",
       "Andorra                                 74.0   \n",
       "Angola                               16557.0   \n",
       "\n",
       "             Population annual growth rate (%)  Population in urban areas (%)  \\\n",
       "Country                                                                         \n",
       "Afghanistan                                4.0                           23.0   \n",
       "Albania                                    0.6                           46.0   \n",
       "Algeria                                    1.5                           64.0   \n",
       "Andorra                                    1.0                           93.0   \n",
       "Angola                                     2.8                           54.0   \n",
       "\n",
       "                         ...                Total_CO2_emissions  Total_income  \\\n",
       "Country                  ...                                                    \n",
       "Afghanistan              ...                             692.50           NaN   \n",
       "Albania                  ...                            3499.12  4.790000e+09   \n",
       "Algeria                  ...                          137535.56  6.970000e+10   \n",
       "Andorra                  ...                                NaN           NaN   \n",
       "Angola                   ...                            8991.46  1.490000e+10   \n",
       "\n",
       "             Total_reserves  Trade_balance_goods_and_services  \\\n",
       "Country                                                         \n",
       "Afghanistan             NaN                               NaN   \n",
       "Albania               78.14                     -2.040000e+09   \n",
       "Algeria              351.36                      4.700000e+09   \n",
       "Andorra                 NaN                               NaN   \n",
       "Angola                27.13                      9.140000e+09   \n",
       "\n",
       "             Under_five_mortality_from_CME  Under_five_mortality_from_IHME  \\\n",
       "Country                                                                      \n",
       "Afghanistan                         257.00                           231.9   \n",
       "Albania                              18.47                            15.5   \n",
       "Algeria                              40.00                            31.2   \n",
       "Andorra                                NaN                             NaN   \n",
       "Angola                              164.10                           242.5   \n",
       "\n",
       "             Under_five_mortality_rate  Urban_population  \\\n",
       "Country                                                    \n",
       "Afghanistan                     257.00         5740436.0   \n",
       "Albania                          18.47         1431793.9   \n",
       "Algeria                          40.00        20800000.0   \n",
       "Andorra                            NaN               NaN   \n",
       "Angola                          164.10         8578749.0   \n",
       "\n",
       "             Urban_population_growth  Urban_population_pct_of_total  \n",
       "Country                                                              \n",
       "Afghanistan                     5.44                           22.9  \n",
       "Albania                         2.21                           45.4  \n",
       "Algeria                         2.61                           63.3  \n",
       "Andorra                          NaN                            NaN  \n",
       "Angola                          4.14                           53.3  \n",
       "\n",
       "[5 rows x 356 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without noise:\n",
      "MIC 1.0\n",
      "MAS 0.726071574374\n",
      "MEV 1.0\n",
      "MCN (eps=0) 4.58496250072\n",
      "MCN (eps=1-MIC) 4.58496250072\n",
      "GMIC 0.779360251901\n",
      "TIC 67.6612295532\n",
      "\n",
      "With noise:\n",
      "MIC 0.505716693417\n",
      "MAS 0.365399904262\n",
      "MEV 0.505716693417\n",
      "MCN (eps=0) 5.95419631039\n",
      "MCN (eps=1-MIC) 3.80735492206\n",
      "GMIC 0.359475501353\n",
      "TIC 28.7498326953\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import minepy\n",
    "\n",
    "def print_stats(mine):\n",
    "    print \"MIC\", mine.mic()\n",
    "    print \"MAS\", mine.mas()\n",
    "    print \"MEV\", mine.mev()\n",
    "    print \"MCN (eps=0)\", mine.mcn(0)\n",
    "    print \"MCN (eps=1-MIC)\", mine.mcn_general()\n",
    "    print \"GMIC\", mine.gmic()\n",
    "    print \"TIC\", mine.tic()\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = np.sin(10 * np.pi * x) + x\n",
    "mine = MINE(alpha=0.6, c=15, est=\"mic_approx\")\n",
    "mine.compute_score(x, y)\n",
    "\n",
    "print \"Without noise:\"\n",
    "print_stats(mine)\n",
    "print\n",
    "\n",
    "np.random.seed(0)\n",
    "y +=np.random.uniform(-1, 1, x.shape[0]) # add some noise\n",
    "mine.compute_score(x, y)\n",
    "\n",
    "print \"With noise:\"\n",
    "print_stats(mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b17e9f06229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s40</th>\n",
       "      <th>s41</th>\n",
       "      <th>s42</th>\n",
       "      <th>s43</th>\n",
       "      <th>s44</th>\n",
       "      <th>s45</th>\n",
       "      <th>s46</th>\n",
       "      <th>s47</th>\n",
       "      <th>s48</th>\n",
       "      <th>s49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o0</th>\n",
       "      <td>198.771721</td>\n",
       "      <td>3.152505</td>\n",
       "      <td>5.300961</td>\n",
       "      <td>1.040519</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>119.083014</td>\n",
       "      <td>2.759216</td>\n",
       "      <td>6.296837</td>\n",
       "      <td>24.684921</td>\n",
       "      <td>...</td>\n",
       "      <td>2.691605</td>\n",
       "      <td>6.120082</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.078959</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.623511</td>\n",
       "      <td>1.586171</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.361753</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>3.321683</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>14.547536</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>5.572708</td>\n",
       "      <td>5.507811</td>\n",
       "      <td>76.736404</td>\n",
       "      <td>252.421404</td>\n",
       "      <td>0.495792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998561</td>\n",
       "      <td>6.977364</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.097206</td>\n",
       "      <td>113.208039</td>\n",
       "      <td>23.398924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2</th>\n",
       "      <td>18.844365</td>\n",
       "      <td>26.817121</td>\n",
       "      <td>0.281691</td>\n",
       "      <td>2.765379</td>\n",
       "      <td>1.148441</td>\n",
       "      <td>301.224127</td>\n",
       "      <td>0.709311</td>\n",
       "      <td>0.525458</td>\n",
       "      <td>2.255277</td>\n",
       "      <td>0.736817</td>\n",
       "      <td>...</td>\n",
       "      <td>11.638839</td>\n",
       "      <td>0.542997</td>\n",
       "      <td>34.513298</td>\n",
       "      <td>96.122554</td>\n",
       "      <td>1.770100</td>\n",
       "      <td>8.301042</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.120505</td>\n",
       "      <td>764.570210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>831.041387</td>\n",
       "      <td>0.495272</td>\n",
       "      <td>1.369084</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>2.127379</td>\n",
       "      <td>146.806717</td>\n",
       "      <td>30.245363</td>\n",
       "      <td>0.639396</td>\n",
       "      <td>...</td>\n",
       "      <td>3.613371</td>\n",
       "      <td>4.198004</td>\n",
       "      <td>209.392156</td>\n",
       "      <td>0.472891</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.404060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o4</th>\n",
       "      <td>271.150487</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>1.982106</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>0.784715</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>8.119664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>12.508647</td>\n",
       "      <td>1.098576</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>2.347198</td>\n",
       "      <td>16.698330</td>\n",
       "      <td>2.672506</td>\n",
       "      <td>22.992043</td>\n",
       "      <td>2.639005</td>\n",
       "      <td>2.675739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s0         s1         s2        s3        s4          s5  \\\n",
       "#OTU ID                                                                     \n",
       "o0       198.771721   3.152505   5.300961  1.040519  0.010064    0.007758   \n",
       "o1         3.321683   0.902373  14.547536  0.693617  0.005882    5.572708   \n",
       "o2        18.844365  26.817121   0.281691  2.765379  1.148441  301.224127   \n",
       "o3       831.041387   0.495272   1.369084  0.170521  0.056409    0.097589   \n",
       "o4       271.150487   0.352624   1.982106  0.068054  0.784715    0.568776   \n",
       "\n",
       "                 s6          s7          s8         s9     ...            s40  \\\n",
       "#OTU ID                                                    ...                  \n",
       "o0       119.083014    2.759216    6.296837  24.684921     ...       2.691605   \n",
       "o1         5.507811   76.736404  252.421404   0.495792     ...       0.998561   \n",
       "o2         0.709311    0.525458    2.255277   0.736817     ...      11.638839   \n",
       "o3         2.127379  146.806717   30.245363   0.639396     ...       3.613371   \n",
       "o4         0.026448    0.077726    0.005434   8.119664     ...       0.000547   \n",
       "\n",
       "               s41         s42        s43       s44        s45       s46  \\\n",
       "#OTU ID                                                                    \n",
       "o0        6.120082    0.051975   0.078959  0.092821   0.623511  1.586171   \n",
       "o1        6.977364    0.006615   0.272016  0.057573   0.026255  0.002019   \n",
       "o2        0.542997   34.513298  96.122554  1.770100   8.301042  0.004804   \n",
       "o3        4.198004  209.392156   0.472891  0.138500   0.084360  0.065644   \n",
       "o4       12.508647    1.098576   0.027195  2.347198  16.698330  2.672506   \n",
       "\n",
       "               s47         s48         s49  \n",
       "#OTU ID                                     \n",
       "o0        0.015250    0.361753    0.037288  \n",
       "o1        0.097206  113.208039   23.398924  \n",
       "o2        0.001146    0.120505  764.570210  \n",
       "o3        0.027368    0.020933    0.404060  \n",
       "o4       22.992043    2.639005    2.675739  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/KevinBu/Desktop/Clemente Lab/CUtIe/data/simulated_data/input_tables/ts_1/txts_cutie/copula_table1_n50_lognorm_3_0_indep.txt\", \n",
    "                 delimiter = '\\t', \n",
    "                 skiprows = 1)\n",
    "df = df.set_index(list(df)[0])\n",
    "#df = df.T\n",
    "#df = df.dropna(how = 'any', axis = 0)\n",
    "#df = df.set_index(list(df)[0])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import minepy\n",
    "test = minepy.pstats(df, alpha=0.6, c=15, est=\"mic_approx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>...</th>\n",
       "      <th>s40</th>\n",
       "      <th>s41</th>\n",
       "      <th>s42</th>\n",
       "      <th>s43</th>\n",
       "      <th>s44</th>\n",
       "      <th>s45</th>\n",
       "      <th>s46</th>\n",
       "      <th>s47</th>\n",
       "      <th>s48</th>\n",
       "      <th>s49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o0</th>\n",
       "      <td>198.771721</td>\n",
       "      <td>3.152505</td>\n",
       "      <td>5.300961</td>\n",
       "      <td>1.040519</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>119.083014</td>\n",
       "      <td>2.759216</td>\n",
       "      <td>6.296837</td>\n",
       "      <td>24.684921</td>\n",
       "      <td>...</td>\n",
       "      <td>2.691605</td>\n",
       "      <td>6.120082</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>0.078959</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.623511</td>\n",
       "      <td>1.586171</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.361753</td>\n",
       "      <td>0.037288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>3.321683</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>14.547536</td>\n",
       "      <td>0.693617</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>5.572708</td>\n",
       "      <td>5.507811</td>\n",
       "      <td>76.736404</td>\n",
       "      <td>252.421404</td>\n",
       "      <td>0.495792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998561</td>\n",
       "      <td>6.977364</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.097206</td>\n",
       "      <td>113.208039</td>\n",
       "      <td>23.398924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2</th>\n",
       "      <td>18.844365</td>\n",
       "      <td>26.817121</td>\n",
       "      <td>0.281691</td>\n",
       "      <td>2.765379</td>\n",
       "      <td>1.148441</td>\n",
       "      <td>301.224127</td>\n",
       "      <td>0.709311</td>\n",
       "      <td>0.525458</td>\n",
       "      <td>2.255277</td>\n",
       "      <td>0.736817</td>\n",
       "      <td>...</td>\n",
       "      <td>11.638839</td>\n",
       "      <td>0.542997</td>\n",
       "      <td>34.513298</td>\n",
       "      <td>96.122554</td>\n",
       "      <td>1.770100</td>\n",
       "      <td>8.301042</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.120505</td>\n",
       "      <td>764.570210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>831.041387</td>\n",
       "      <td>0.495272</td>\n",
       "      <td>1.369084</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>2.127379</td>\n",
       "      <td>146.806717</td>\n",
       "      <td>30.245363</td>\n",
       "      <td>0.639396</td>\n",
       "      <td>...</td>\n",
       "      <td>3.613371</td>\n",
       "      <td>4.198004</td>\n",
       "      <td>209.392156</td>\n",
       "      <td>0.472891</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.404060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o4</th>\n",
       "      <td>271.150487</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>1.982106</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>0.784715</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>8.119664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>12.508647</td>\n",
       "      <td>1.098576</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>2.347198</td>\n",
       "      <td>16.698330</td>\n",
       "      <td>2.672506</td>\n",
       "      <td>22.992043</td>\n",
       "      <td>2.639005</td>\n",
       "      <td>2.675739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s0         s1         s2        s3        s4          s5  \\\n",
       "#OTU ID                                                                     \n",
       "o0       198.771721   3.152505   5.300961  1.040519  0.010064    0.007758   \n",
       "o1         3.321683   0.902373  14.547536  0.693617  0.005882    5.572708   \n",
       "o2        18.844365  26.817121   0.281691  2.765379  1.148441  301.224127   \n",
       "o3       831.041387   0.495272   1.369084  0.170521  0.056409    0.097589   \n",
       "o4       271.150487   0.352624   1.982106  0.068054  0.784715    0.568776   \n",
       "\n",
       "                 s6          s7          s8         s9     ...            s40  \\\n",
       "#OTU ID                                                    ...                  \n",
       "o0       119.083014    2.759216    6.296837  24.684921     ...       2.691605   \n",
       "o1         5.507811   76.736404  252.421404   0.495792     ...       0.998561   \n",
       "o2         0.709311    0.525458    2.255277   0.736817     ...      11.638839   \n",
       "o3         2.127379  146.806717   30.245363   0.639396     ...       3.613371   \n",
       "o4         0.026448    0.077726    0.005434   8.119664     ...       0.000547   \n",
       "\n",
       "               s41         s42        s43       s44        s45       s46  \\\n",
       "#OTU ID                                                                    \n",
       "o0        6.120082    0.051975   0.078959  0.092821   0.623511  1.586171   \n",
       "o1        6.977364    0.006615   0.272016  0.057573   0.026255  0.002019   \n",
       "o2        0.542997   34.513298  96.122554  1.770100   8.301042  0.004804   \n",
       "o3        4.198004  209.392156   0.472891  0.138500   0.084360  0.065644   \n",
       "o4       12.508647    1.098576   0.027195  2.347198  16.698330  2.672506   \n",
       "\n",
       "               s47         s48         s49  \n",
       "#OTU ID                                     \n",
       "o0        0.015250    0.361753    0.037288  \n",
       "o1        0.097206  113.208039   23.398924  \n",
       "o2        0.001146    0.120505  764.570210  \n",
       "o3        0.027368    0.020933    0.404060  \n",
       "o4       22.992043    2.639005    2.675739  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124750"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC_p = test[0]\n",
    "# i < j < m, MIC between row i and row j\n",
    "# stored in k = m*i - i*(i+1)/2 - i - 1 + j\n",
    "len(MIC_p)\n",
    "\n",
    "import numpy as np\n",
    "with open('/Users/KevinBu/Desktop/Clemente Lab/CUtIe/data/MINE/n=50,alpha=0.6.csv', 'rU') as f:\n",
    "    MINE_bins, pvalue_bins = parse_minep(f, delimiter = ',', pskip = 13)\n",
    "\n",
    "# convert MIC_p into full MIC_str array\n",
    "MIC_str = np.zeros(shape=[n_var,n_var])\n",
    "for i in xrange(n_var):\n",
    "    for j in xrange(n_var):\n",
    "        k = m*i - i*(i+1)/2 - i - 1 + j\n",
    "        MIC_str[i][j] = MIC_p[k]\n",
    "\n",
    "# compute_mine function\n",
    "def compute_mine(new_var1, new_var2, pvalue_bins, mine_str, mine_bins):\n",
    "    # if resulting variables do not contain enough points\n",
    "    if new_var1.size < 2 or new_var2.size < 2:\n",
    "        p_value = 1\n",
    "        r_value = 0\n",
    "    else:\n",
    "        data = np.stack([new_var1, new_var2], 0)\n",
    "        r_value = minepy.pstats(data, alpha=0.6, c=15, est=\"mic_approx\")\n",
    "        p_value = new_str_to_pvalues(pvalue_bins, r_value, mine_bins)\n",
    "        \n",
    "    return p_value, r_value\n",
    "\n",
    "def new_str_to_pvalues(pvalue_bins, mine_str, mine_bins):\n",
    "    found, midpoint = binarySearchBins(pvalue_bins, mine_str)\n",
    "    if found:\n",
    "        mine_p = mine_bins[midpoint][1]\n",
    "    else:\n",
    "        mine_p = 1\n",
    "        \n",
    "    return mine_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resamplek_cutie_mine(var1_index, var2_index, n_samp, samp_var1, samp_var2,\n",
    "                       pvalues, threshold, resample_k, sign, fold, fold_value,\n",
    "                        pvalue_bins, mine_str, mine_bins):\n",
    "  \n",
    "    # initialize indicators and variables\n",
    "    exceeds, reverse, maxp, minr, var1, var2 = init_var_indicators(var1_index,\n",
    "                                            var2_index, samp_var1, samp_var2)\n",
    "\n",
    "    # iteratively delete k samples and recompute statistics\n",
    "    combs = [list(x) for x in itertools.combinations(xrange(n_samp), resample_k)]\n",
    "    for indices in combs:\n",
    "        new_var1 = var1[~np.in1d(range(len(var1)),indices)]\n",
    "        new_var2 = var2[~np.in1d(range(len(var2)),indices)]\n",
    "       \n",
    "        # remove NaNs\n",
    "        new_var1, new_var2 = remove_nans(new_var1, new_var2)\n",
    "\n",
    "        # compute new p_value and r_value\n",
    "        p_value, r_value = compute_mine(new_var1, new_var2, pvalue_bins, mine_str, mine_bins)\n",
    "\n",
    "        # update reverse, maxp, and minr\n",
    "        reverse, maxp, minr = update_rev_maxp_minr(sign, r_value, p_value,\n",
    "                                                   indices, reverse, maxp, minr)\n",
    "        \n",
    "        if fold:\n",
    "            if (p_value > threshold and \\\n",
    "                p_value > pvalues[var1_index][var2_index] * fold_value) or \\\n",
    "                np.isnan(p_value):\n",
    "                for i in indices:\n",
    "                    exceeds[i] += 1\n",
    "        elif p_value > threshold or np.isnan(p_value): \n",
    "            for i in indices:\n",
    "                exceeds[i] += 1\n",
    "\n",
    "    return reverse, exceeds, maxp, minr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_minep(pvalue_fp, delimiter = ',', pskip = 13):\n",
    "    \"\"\"\n",
    "    INTPUTS\n",
    "    pvalue_fp: table of pvalue-MICstrength relationship provided by MINE\n",
    "    delimiter: ',' MINE uses csv files by default\n",
    "    pskip:     number of rows to skip in the pvalue table (various comments)\n",
    "\n",
    "    OUTPUTS\n",
    "    MINE_bins:       array where each row has [MIC_str, pvalue, stderr of pvalue]\n",
    "                     (pvalue corresponds to probability of observing MIC_str as and \n",
    "                     more extreme as observed MIC_str)\n",
    "    pvalues_ordered: sorted list of pvalues from greatest to least used by MINE \n",
    "                     to bin\n",
    "\n",
    "    FUNCTION\n",
    "    Parses a MINE pvalue table into bins that relate MIC-str to pvalue\n",
    "    \"\"\"\n",
    "    # initialize lists\n",
    "    MINE_bins = []\n",
    "    pvalues_ordered = []\n",
    "    # skip comments\n",
    "    for i in xrange(pskip):\n",
    "        pvalue_fp.readline()\n",
    "    # parse file\n",
    "    for line in pvalue_fp.readlines():\n",
    "        # example line: 1.000000,0.000000256,0.000000181\n",
    "        # corresonding to [MIC_str, pvalue, stderr of pvalue]\n",
    "        split_line = line.rstrip().split(delimiter)\n",
    "        # make sure line is valid; last line is 'xla' \n",
    "        if len(split_line) > 1:\n",
    "            row = [float(x) for x in split_line]\n",
    "            MINE_bins.append(row)\n",
    "            pvalues_ordered.append(row[0]) # row[0] is the pvalue\n",
    "\n",
    "    # convert list to array\n",
    "    MINE_bins = np.array(MINE_bins)\n",
    "\n",
    "    return MINE_bins, pvalues_ordered \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32297764255298839"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC_p[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29257366  0.38677239  0.25509445  0.32297764  0.3120421   0.384384\n",
      "  0.29087946  0.34987163  0.22419503  0.30041528]\n",
      "[[ 1.          0.29257366  0.38677239  0.25509445  0.32297764]\n",
      " [ 0.29257366  1.          0.3120421   0.384384    0.29087946]\n",
      " [ 0.38677239  0.3120421   1.          0.34987163  0.22419503]\n",
      " [ 0.25509445  0.384384    0.34987163  1.          0.30041528]\n",
      " [ 0.32297764  0.29087946  0.22419503  0.30041528  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import minepy\n",
    "test = minepy.pstats(df.head(), alpha=0.6, c=15, est=\"mic_approx\")\n",
    "MIC_p = test[0]\n",
    "print MIC_p\n",
    "n_var = 5\n",
    "MIC_str = np.zeros(shape=[n_var,n_var])\n",
    "for i in xrange(n_var):\n",
    "    for j in xrange(n_var):\n",
    "        if i == j:\n",
    "            MIC_str[i][j] = 1\n",
    "        elif i < j:\n",
    "            k = abs(n_var*i - i*(i+1)/2 - i - 1 + j)\n",
    "            MIC_str[i][j] = MIC_p[k]\n",
    "            MIC_str[j][i] = MIC_p[k]\n",
    "        \n",
    "print MIC_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
